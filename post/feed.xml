<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on tellme.tokyo</title>
    <link>https://tellme.tokyo/post/</link>
    <description>Recent content in Posts on tellme.tokyo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>BABAROT All Right Reserved.</copyright>
    <lastBuildDate>Sun, 31 Dec 2023 17:44:22 +0900</lastBuildDate><atom:link href="https://tellme.tokyo/post/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2023年振り返り</title>
      <link>https://tellme.tokyo/post/2023/12/31/2023-review/</link>
      <pubDate>Sun, 31 Dec 2023 17:44:22 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2023/12/31/2023-review/</guid>
      <description>転職して2年経った 2022年1月に転職して 10X に入社した。SRE として入社してリライアビリティ &amp;amp; セキュリティ部に所属している。今年は色々なことがあった
 EM になって1年以上経った 部長になった SLO を真剣にやった チームマネジメントちゃんと思考し始めた (IC→Mgr) リライアビリティとセキュリティの両方で成果が出るような体制づくりを始めた  良い意味で忙しくできているので会社のブログも個人のブログも書けていない (書きたい)。来年は成果の取り組みとかをアウトプットしていきたい。
EM を1年やった 2022年の10月から Engineering Manager を引き受けることになったのでかれこれ1年以上経過した。夏頃には部長にもなった。&amp;ldquo;部長&amp;quot;というと大層なロールに感じるが、10X では Tech Lead を置いていないので部の技術的な意思決定とピープルマネジメントの両方をやる役職が部長となっている。
前職では人の評価をする人間になるとはこれっぽちも思っていなかったが、当時の Mgr が育休に入ることになってバトンタッチして引き受けることになった。もともと技術が好きでソフトウェアエンジニアになったつもりでいたんだけど、EM をお願いされたときは不思議と嫌な気分はしなかった。なんでかなと思ったら作っているプロダクトに興味があって事業が大きくなったりプロダクトがうまくいく (ために技術を使う) ことが好きなのであって、技術自体が HOW なわけではないからだと気づいた。なので結果として楽しく EM 業ができている。経験自体はないのでインプットしながら試行錯誤はしている。
Z 買った (車買い替えた) RZ34型のフェアレディZ。発売してすぐの2022年7月末で受注停止になってしまい現在なお再開されていない。2023年12月時点でバックオーダーに6000台以上あって毎月60-100台程度しか生産できておらず(登録台数)このペースだとバックオーダーの納車まで4年以上かかる。
Zの発表時はかっこいいなあとは思ったけど、まさか現行でスポーツカーを買うとは思ってなかった。というのも小さいときから憧れのクルマだったR34スカイラインにずっと乗りたかったから。けれど25年近く経つため内外装の状態や価格面とかで諸々条件に見合うものに巡り会えずにいた。
そんなときZ NISMOの追加が発表されてますます興味出てきて、日産グローバル本社行って試乗したりしてた。そのときはまだいいなぁくらいだったけどNDロードスター(6MT)に数日乗る機会があって乗ったら久しぶりに乗ったMTがめちゃ楽しくて今すぐMT乗りたいと思った。R34買うまで待てなくてとりあえずMT乗りたい欲でソワソワしてたときに、そうだ、Zあるじゃんとおもって取り扱ってるお店に行って即契約した。
契約したZは20kmしか走ってないいわゆる登録済み未使用車で、納車時のビニールとかも被ったようなほぼ新車。最高の状態だった。バージョンSTのプロトスペック6速MT。240台しか生産されていない限定車。それも購入の決め手だった。前オーナーさんは地元の社長やっている人で乗らずに車庫保管してくれていた。あと次の買い手が20代ということを知って色々と融通して譲ってくれた。
納車して1ヶ月半くらい4500kmくらい走った。とりあえず楽しいクルマ。しばらくはノーマルで乗るつもり。
 ※ R34 は今もほしい。
PFCをコントロールしはじめた PFCを意識した食事を始めた。ジムも行き始めた。長時間何か (外出,ドライブ,旅行,リュックを背負う, &amp;hellip;) をするには体力が必要だと気づいた。あと今年ついに30代にも突入した。筋肉があればまず困ることはないだろうと9月ころから筋トレと食事コントロールを始めた。上半身(胸,肩,背中)と下半身(脚)の2回を週3-4で通ってる。筋肉の作り変わりの周期的にあと1−2ヶ月しないと実感する効果は出てこないが、まずは一生続けられるようにひたすら打ち込んでいる。
目安1600kcal
 Pタンパク質 120g 480kcal F脂質 35g 320kcal C炭水化物 200g 800kcal  使っているアプリはカロミル。課金もしてかなりいい感じに (ラクに) 食事管理ができている。</description>
    </item>
    
    <item>
      <title>gh extension の管理</title>
      <link>https://tellme.tokyo/post/2023/03/21/manage-gh-extensions/</link>
      <pubDate>Tue, 21 Mar 2023 13:46:10 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2023/03/21/manage-gh-extensions/</guid>
      <description>gh GitHub が公式で開発している GitHub CLI クライアントである gh コマンドが cli/cli で公開されているのだが今まで使ってこなかった。
そんなある日、いつものようにMarkdown を書いていると、見慣れた GitHub の CSS でプレビューしたいな (N 度目) と思いいくつかの Markdown エディタで GitHub テーマを適用してほぼオリジナルに近いプレビューできるのはどれだと探してきたが、どこかしら微妙に違ってまだ出ていないかと諦めていた。
そんなときにこのブログを見た。
READMEをpush前にプレビューできるGitHub CLI拡張を作った - ゆーすけべー日記
 めっちゃ GitHub。Live-reloading もできるし「これだよ! これ!」という感じ。どうやら gh コマンドの拡張機能 (extension) として公開されているらしい。
yusukebe/gh-markdown-preview
$ gh extension install yusukebe/gh-markdown-preview これでインストールができる。めっちゃかんたん。ここで gh extension というのがあるのだと知り、探してみると色々あることに気づく。gh コマンドが出た当初はこんなものはなかった気がするので、自分が使わなかったうちに相当開発が進んでいたらしい。
GitHub CLI extension
そうなると色々試したくなる。おもしろそうと思って色々インストールしているうちにたくさんになった。
$ gh extension list gh branch mislav/gh-branch b2e79733 gh dash dlvhdr/gh-dash 50cd7818 gh md yusukebe/gh-markdown-preview v1.4.0 gh poi seachicken/gh-poi v0.</description>
    </item>
    
    <item>
      <title>転職して1年が経つので振り返り。来年の抱負など</title>
      <link>https://tellme.tokyo/post/2022/12/28/10x-1st-y-aniv/</link>
      <pubDate>Wed, 28 Dec 2022 11:47:42 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2022/12/28/10x-1st-y-aniv/</guid>
      <description>この記事は 10X アドベントカレンダー2022 28日目のエントリーです。
シリーズ共通のお題、「好きなスーパーと商品は？」について。好きなスーパーはクイーンズ伊勢丹です。高輪に住んでいたとき最初はほかに選択肢がなく利用しはじめたのですが、通うたびに気になる商品に出会うことが多く好きになりました。好きな商品は石野味噌です。天明元年から続く歴史ある白味噌です。
今回のエントリーの投稿に際し、ちょうど転職をして1年になるので入社から今までのタイムラインの振り返りと、来年以降の自分の考えについて書き留めておきます。
2022/1 チームづくり 退職と転職。人生の振り返り
今年の1月に 10X へ転職しました。10X では初の SRE Job description での採用ということで、チーム作りや Stailer 事業の拡大を支えるインフラづくりやそのビジョンを描くために入社しました。詳しくは上のエントリにあります。
入社してから4月ころまではチームビルディングやロードマップづくりなどから始まり、今後さらに広がっていく Stailer 事業のパートナー展開をインフラ面からどのように支えられるのか、スケールに耐えられる基盤のデザインが中心でした。
  Datadog 導入 Kubernetes Cluster のデザイン Kubernetes manifest management のデザイン Incident 対応のワークフロー整備 Terraform 導入検討 デプロイの高速化、リリースフローの刷新 &amp;hellip;  10X に SRE Team ができるまでとこれから - 10X Product Blog より抜粋
 2022/4 大きな種まき 4月からは新しい FY がスタートし、前 Q に設定したロードマップをベースに事業マイルストーンから逆算した種まき的な施策を進めました。前 Q はチーム作りを筆頭としてデザインやコトモノの言語化、文化づくりなどが主でしたが、4月からの Q1 はシステム構成に手を加えるような施策や前 Q で PoC したデザインなどを実装・導入するなど、SRE チームとしては大きなインパクトを残すことができた3ヶ月となりました。
 Istio の削除  Too much な構成からよりメンテナブルな構成に変更   メインクラスタの Namespace 設計  パートナーごとの isolation を意識して分割、リソースの引っ越し   Terraform の導入  既存インフラのコード化と apply ワークフローのデザイン・構築   Terraform module の作成  パートナーローンチごとに設定していたインフラのリソースセット (GCP/PagerDuty/GitHub/&amp;hellip;) を一撃で準備できるように   SLI/SLO の策定 オーナーシップづくり  各パートナー開発部が開発と運用、両方にオーナーシップをもてるような構成変更 また、オーナーシップを持つことがどのように重要なのかを全社的に説明    事業スケール確実のタイムラインが見えている中、中長期的に効いてくるものから優先的に着手しました。エンジニア全体に広めに付与されていた権限を整理し、権限ください依頼やリソース作成の依頼など SRE がボトルネックになっていた作業を自分たちでできるようにするために Terraform によるインフラのコード化を行い、またパートナーの横展開がしやすいように module による自動化を進めたり、過去の歴史的経緯によって生まれそしてそのまま残ってしまっている直したい部分をきれいにするなどをすすめました。</description>
    </item>
    
    <item>
      <title>Terraform の object variable で柔軟なパラメータ設定を提供する (optional default)</title>
      <link>https://tellme.tokyo/post/2022/07/03/terraform-optional-attributes-for-object-type-constraints/</link>
      <pubDate>Sun, 03 Jul 2022 02:55:06 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2022/07/03/terraform-optional-attributes-for-object-type-constraints/</guid>
      <description>object variable の optional default とは Terraform v1.3.0 から object variable の optional default が使えるようになる (現在は experimental で v1.3.0-alpha で利用可能)
 Optional arguments in object variable type definition · Issue #19898 · hashicorp/terraform [Request] module_variable_optional_attrs: Optional default · Issue #30750 · hashicorp/terraform  どういう機能かというと、object type の variable にて、object attribute (object の key に対応する value) で optional() を設定したときに一緒に default value を指定できるようにするもの。
こうすることで optional のパラメータ (object attribute) に対してユーザからの Input がなかった場合、null ではなく指定した default value が使用される。</description>
    </item>
    
    <item>
      <title>Terraform の Variables と Locals、Outputs</title>
      <link>https://tellme.tokyo/post/2022/06/15/terraform-variables-is-api/</link>
      <pubDate>Wed, 15 Jun 2022 00:08:10 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2022/06/15/terraform-variables-is-api/</guid>
      <description>それぞれの役割 Terraform で &amp;ldquo;変数&amp;rdquo; というと、Variables と Locals がある。どちらも値を入れて、Terraform ファイル や Terraform Module から参照することができる。ちなみに Terraform Module とは「.tf ファイルが置かれたディレクトリ」を意味する。main.tf などを置いた瞬間からそのディレクトリは Module として扱われ、起点となる Module を Root Module と呼ぶ。
Terraform では &amp;ldquo;変数&amp;rdquo; 以外に &amp;ldquo;返り値&amp;rdquo; (Return value) に相当するものとして Outputs がある。これは Module での処理結果を Module 外から参照できるようにするために使うものである。
それぞれについて公式ドキュメントでは次のように紹介されている。
 Input Variables serve as parameters for a Terraform module, so users can customize behavior without editing the source. Output Values are like return values for a Terraform module. Local Values are a convenience feature for assigning a short name to an expression.</description>
    </item>
    
    <item>
      <title>Terraform の count と for_each の使い分けと Splat Expressions について</title>
      <link>https://tellme.tokyo/post/2022/06/12/terraform-count-for-each/</link>
      <pubDate>Sun, 12 Jun 2022 00:03:43 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2022/06/12/terraform-count-for-each/</guid>
      <description>count と for_each Terraform には &amp;ldquo;繰り返す&amp;rdquo; 処理として count と for_each がある。
resource &amp;#34;aws_instance&amp;#34; &amp;#34;server&amp;#34; { count = 4# create four similar EC2 instances  ami = &amp;#34;ami-a1b2c3d4&amp;#34; instance_type = &amp;#34;t2.micro&amp;#34; tags = { Name = &amp;#34;Server ${count.index}&amp;#34; } } resource &amp;#34;aws_iam_user&amp;#34; &amp;#34;the-accounts&amp;#34; { for_each = toset( [&amp;#34;Todd&amp;#34;, &amp;#34;James&amp;#34;, &amp;#34;Alice&amp;#34;, &amp;#34;Dottie&amp;#34;] ) name = each.key } どちらも for ループとして利用できるが count はリソースを配列として作成し、for_each はマップとして作成する (リソースは state に保存されこのときの状態の持ち方が配列とマップという違いがある)。また、for_each では配列とマップの型を渡すことができ、配列を渡す場合は明示的に toset で Set (重複する値がないことが保証された配列) に変換して渡す必要がある。マップはそのまま渡す。</description>
    </item>
    
    <item>
      <title>新しいコマンドラインツール向けのパッケージマネージャ</title>
      <link>https://tellme.tokyo/post/2022/03/02/package-manager-for-cli/</link>
      <pubDate>Wed, 02 Mar 2022 20:35:20 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2022/03/02/package-manager-for-cli/</guid>
      <description>最近、afx という CLI 向けのパッケージマネージャを公開した。ここで &amp;ldquo;CLI のパッケージ&amp;rdquo; とは例えば jq のようなコマンドラインツールや zsh-history-substring-search のようなヒストリ補完をするシェルのプラグインを指す (bash/zsh/fish)。afx ではこれらを 1 つのツールで管理すること、コードで表現して管理することを目的としている。コードには YAML を使用する。
また afx では、管理するパッケージとそのツールの設定を一緒に保つことができる。例えば jq 自体の管理とその jq で使う環境変数やエイリアスの設定などを同じ YAML ファイルに記述できる。これによって、各種ツールの設定が bashrc/zshrc などに散乱することや、もう使っていないなどの理由でツール自体はインストールされていないのに設定だけが残っている、みたいなことを防ぐことができる。
# ~/.config/afx/commands.yamlgithub:- name:stedolan/jqdescription:Command-line JSON processorowner:stedolanrepo:jqrelease:name:jqtag:jq-1.6command:link:- from:&amp;#39;*jq*&amp;#39;to:jqalias:jq:jq -Csnippet:|# you can write shell script here # -&amp;gt; define global alias (zsh feature) if [[ $SHELL == *zsh* ]]; then alias -g J=&amp;#39;| jq -C . | less -F&amp;#39; fi# ~/.config/afx/plugins.yamlgithub:- name:b4b4r07/enhancddescription:A next-generation cd command with your interactive filterowner:b4b4r07repo:enhancdplugin:env:ENHANCD_FILTER:fzf --height 25% --reverse --ansi:fzy:pecosources:- init.</description>
    </item>
    
    <item>
      <title>退職と転職。人生の振り返り</title>
      <link>https://tellme.tokyo/post/2022/02/28/mercari-to-10x/</link>
      <pubDate>Mon, 28 Feb 2022 21:00:12 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2022/02/28/mercari-to-10x/</guid>
      <description>お久しぶりです。
2021年12月末でメルカリを退職しました。在籍期間は5年8ヶ月でした。2022年1月からは 10X で SRE をやっています。メルカリはファーストキャリアで第1期新卒としての入社でした。メルカリで働いたことは自分の人生に大きな影響があったこと、退職したことは大きな決断だったので振り返りを残します。
2016年 2016年に新卒としてメルカリに入社しました。GitHub 採用というやつです。当時は相当前衛的でヤバイ組織だなという印象を持ちました。
配属先は「JP チーム」という名前のチームで、バックエンドエンジニアとしてでした。JP チームの API 開発エンジニアとしては3人目の入社で、当時の JP チームはデザインメンバーからプロデューサー (当時の呼称) までが10人前後集まった集団でした。プロダクトサイドのメンバーとしてはもっといたのですが、当時は「US ファースト」で開発リソースの9割近くが US 事業に割かれていました。入社前は外から CM などを通してみるメルカリは大きく伸び始めている企業で、優秀な人がたくさん働いているのだろうなとぼんやり思っていたのですが、入社して蓋を開けてみるとこれほどまでに少ない人員で運営していたのかと驚きました。 JP は多くの利益を生むメルカリグループ全体の収益基盤にもかかわらず、小さなチームで運営していたことに驚いたと同時に、足を引っ張らぬよう気を引き締めたことを覚えています。業務内容は主に「○月くじ」や CM 連動型のキャンペーンなどでした。
同年9月頃に新卒エンジニア3人が1ヶ月間代わる代わるメルカリの SRE 業務を体験するという SRE 研修が始まりました。当時の SRE チームと SRE メンバーの視点を養うということで始まった研修ですが、サブタスクとして好きな業務改善に取り組むことができました。自分は IP DB と呼ばれていた Go で書かれたサーバを net/http を使って書き直すことに取り組みました。
研修後は JP チームに戻り色々な業務を担当しました。1番覚えているのは CS ツールの電話対応でした。エスカレされてきたお客様同士の重大なトラブルなどについては CS が電話で応対できるようにするといったものです。はじめて一任されたデカメのタスクで、実装や QA などで大変だった一方で、福岡に電話対応チームが発足するということもあり楽しかった思い出があります。
その後は自分も US 配属となりました。より一層 US 事業に力を入れる必要がある必要が出てきたためです。当時は US アプリのリデザインとアーキテクチャの刷新が図られていました。API サイドでは PHP で書かれた API のコードベースに Go で書かれた API ラッパーを挟むという大工事が始まっていました。これは後に US が JP ベースの PHP コードからラッパーを介して Go で書き直された各種機能（マイクロサービス）にスイッチングすることを担っていました。</description>
    </item>
    
    <item>
      <title>標準出力に出しつつ、パイプ先のコマンドにも繋ぐ</title>
      <link>https://tellme.tokyo/post/2020/02/07/tee-command/</link>
      <pubDate>Fri, 07 Feb 2020 12:27:21 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2020/02/07/tee-command/</guid>
      <description>コマンドの結果を目で見ながら、パイプに渡すなどするときのこと。
よくやるのに忘れるのでメモする。
結論 some-command | tee &amp;gt;(pipe-command) 解説 tee コマンドを使うとできる。
肝は tee が input されたデータを、
 標準出力 リダイレクト先  これらに output することができるので、リダイレクト先をプロセス置換1を使ってパイプに渡したいコマンドを指定することで標準出力に出しつつ、特定のコマンドにパイプすることができる。
実際のデモ:
seq 15 | tee &amp;gt;(grep 4) tee は標準出力ではなく、標準エラー出力にも出すことができる。 普通に file descriptor 2番に出力する。
seq 15 | tee &amp;gt;(grep 4) &amp;gt;&amp;amp;2 # もしくは seq 15 | tee &amp;gt;&amp;amp;2 &amp;gt;(grep 4) よくやるシーンとして、CI のコンソールにも出しつつ、結果を GitHub コメントに POST する、といったときにやる。
notify() { local comment template comment=&amp;#34;$(tee &amp;gt;(cat)&amp;gt;&amp;amp;2)&amp;#34; # pipe and output stderr template=&amp;#34;## Some results \`\`\` %s \`\`\` &amp;#34; comment=&amp;#34;$(printf &amp;#34;${template}&amp;#34; &amp;#34;${comment}&amp;#34;)&amp;#34; github_comment &amp;#34;${comment}&amp;#34; } some_output_func | notify mercari/tfnotify も最初はこういう感じのシェルスクリプトから始まったことを思い出した。</description>
    </item>
    
    <item>
      <title>Go で書いた CLI ツールのリリースは GoReleaser と GitHub Actions で個人的には決まり</title>
      <link>https://tellme.tokyo/post/2020/02/04/release-go-cli-tool/</link>
      <pubDate>Tue, 04 Feb 2020 00:32:10 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2020/02/04/release-go-cli-tool/</guid>
      <description>lt;dr GoReleaser と GitHub Actions を使うと簡単にビルドしたバイナリを作ってアップロードできる。
 2つの YAML を書いてリポジトリにコミットする  .github/workflows/release.yml .goreleaser.yml   git tag して push する バイナリがリリースされる  専用のツールをローカルにインストールする必要はない。
本題 前に、Go のコマンドラインツールを簡単にリリースする | tellme.tokyo というブログを書いた。
それよりももっと楽になったので紹介する。
基本的にこのページで紹介する方法では 2 つの YAML をリポジトリに置くだけで終わる。 ローカルに何かをインストールする必要もない。 2 つの YAML を書くだけ (コピペするだけ) でリリースの準備が整う。
まずはじめに .github/workflows/release.yml を置く。 編集不要でコピペする。
name:releaseon:push:tags:- &amp;#34;v[0-9]+.[0-9]+.[0-9]+&amp;#34;jobs:goreleaser:runs-on:ubuntu-lateststeps:- name:Checkoutuses:actions/checkout@v1with:fetch-depth:1- name:Setup Gouses:actions/setup-go@v1with:go-version:1.13- name:Run GoReleaseruses:goreleaser/goreleaser-action@v1with:version:latestargs:release --rm-distenv:GITHUB_TOKEN:${{ secrets.GITHUB_TOKEN }}つぎに .goreleaser.yml を置く。このファイルはツール名の部分だけリポジトリに沿うように変更する (git-bump のところ)。
project_name:git-bumpenv:- GO111MODULE=onbefore:hooks:- go mod tidybuilds:- main:.binary:git-bumpldflags:- -s -w- -X main.Version={{.Version}}- -X main.</description>
    </item>
    
    <item>
      <title>Cloudflare から GitHub Pages の HTTPS 機能に移行する</title>
      <link>https://tellme.tokyo/post/2020/01/29/migrate-https-gh-pages-from-cloudflare/</link>
      <pubDate>Wed, 29 Jan 2020 23:21:50 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2020/01/29/migrate-https-gh-pages-from-cloudflare/</guid>
      <description>以前は GitHub Pages だけでは HTTPS 配信ができなかったので、Cloudflare をプロキシにして HTTPS 化させていた。
カスタムドメインの GitHub Pages で HTTPS を使う - Qiita
もう必要ないので Cloudflare を通さないようにする。
Before:
Domain-provider DNS -&amp;gt; Cloudflare DNS -&amp;gt; GitHub -&amp;gt; tellme.tokyo After:
Domain-provider DNS -&amp;gt; GitHub -&amp;gt; tellme.tokyo 1. ドメインプロバイダの DNS 設定を Cloudflare からプロバイダ提供のものに変更する Cloudflare DNS を使っていたのを、
 ムームードメインの DNS サーバを使うようにセットアップした。
 2. GitHub Pages への IP アドレスを A レコードに設定する GitHub Pages に向ける。
 参考: GitHub Pages で HTTPS を有効にする | tellme.</description>
    </item>
    
    <item>
      <title>ローカルから Gist を編集する方法</title>
      <link>https://tellme.tokyo/post/2020/01/28/gist-in-local/</link>
      <pubDate>Tue, 28 Jan 2020 22:04:26 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2020/01/28/gist-in-local/</guid>
      <description>コードスニペットなどの管理によく Gist を使う。 他にも特定の人にテキストを共有する目的で日本語を書いて置いておく場としても利用している。
頻繁に読み書きするとなるとウェブから編集するのは少し手間に感じてくる。 構造化された文章を書くなら慣れたエディタで書きたい。 ローカルにコピペしてきてから編集してウェブ画面でペーストしていたこともあるが、頻繁にとなるとこれも結構面倒くさい。
Gist はあくまでも git リポジトリなので git clone して手元で編集して push することもできる。 かといってそれをやるかというとそれもまた面倒。 テキスト編集するだけなのに git fetch も git commit もしたくない。 なるべくそういったことは隠蔽されていてほしい。 どこに clone するかといったことは ghq を使うことで考えなくてよくなるけど根本的な面倒くささは拭えない。
こういったモチベーションからウェブから読み書きするのと同じ体験をローカルで再現するツールを書いた1。
gist という Gist に対して簡単な CRUD 操作ができるツールを Go で書いた。
 gistコマンドは次のサブコマンドを持つ。
   コマンド 説明     new 引数に渡されたファイルを Gist にアップロードする。引数がない場合は tmp ファイルを開き、エディタを閉じたらその内容でアップロードする   open 記事一覧を表示して選択されたファイルの Gist ページをブラウザで開く   edit 記事一覧を表示して選択されたファイルをエディタで開く   delete 記事一覧を表示して選択されたファイルの Gist ページを消す    これらのコマンドは実際に new とか edit する前に内部で次のことをする。</description>
    </item>
    
    <item>
      <title>はてなブログの記事をインポートした</title>
      <link>https://tellme.tokyo/post/2020/01/28/import-hatena-blog/</link>
      <pubDate>Tue, 28 Jan 2020 00:11:10 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2020/01/28/import-hatena-blog/</guid>
      <description>動機はこれ。
テキストの引越し
今まで、
 Qiita はてなブログ GitHub (このブログ)  に文章を書いてきた。
Medium とか他にもどこかに書いていたような気もするけど気にしないことにした (といいつつ Note は使ってみたいと思っている)。
はてなブログに関しては1度作って消してまたやり直している。 そのときに2014年頃以前のテキストを失った。 これからはすべて GitHub で管理しようと思っている。 自分のブログが1番落ち着くし、どんな話題でも好きに書けるし、サービス終了を気にする必要もないし、ホスティングの乗り換えも簡単にできる (今は GitHub Pages を使ってるけど Netlify にもいけるし適当なサーバでもよい)。
そういえばこのブログ以外にも以前 GitHub でいくつか文章を書いていたこともあった。
Qiita も以前はよく使っていたけどもう使っていないし、はてなブログも使っていない。 Qiita の記事も移行するかどうかは未定1だけど、はてなブログにある記事は愛着もあるので全部移行することにした。
 移行に使ったのはこれ。
 これはもともとローカルに引っ張ってきて更新してブログに Sync するようなツールっぽいけど、これのおかげで自分で生 API 叩かずに手元に全エントリを引っ張ってこれたので使い勝手が良かった。
そのあとは適当に YAML の Front matter をこのブログ用に書き換えて終わり。 画像は自力でダウンロードして GitHub のディレクトリに突っ込んだ。 数が少なかったのと一部の画像ははてなにアップロードせずに CloudApp を使って参照させていたので移行する必要がなかったのも大きい。
とりあえず引っ越した記事に Front matter にはインポート元を書いて、こっちのページから辿れるようにはしてある (oldlink という Front matter 要素を作って、記事 Body に 元記事 というリンク href を埋め込む)。 けど、インポートも済んだことだし気が向いたらはてなブログ自体を消すかもしれない。</description>
    </item>
    
    <item>
      <title>GitHub Pages で HTTPS を有効にする</title>
      <link>https://tellme.tokyo/post/2020/01/20/github-pages-with-https/</link>
      <pubDate>Mon, 20 Jan 2020 19:58:54 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2020/01/20/github-pages-with-https/</guid>
      <description>GitHub Pages で静的ページを公開するのが簡単なのでよく使う。 これまで公開したサイトの HTTPS 化は Cloudfrare でやっていた。1 めんどくさくて移行していなかったんだけど HTTPS 化するのも GitHub Pages の設定画面からできるようなのでやっていく2。
1. IP をレジストラに追加する 公式ガイドにある通り、GitHub の A レコードをすべて登録する。
185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153   待っていると数分でつながるようになる。
$ dig babarot.me +nostats +nocomments +nocmd ; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.10.6 &amp;lt;&amp;lt;&amp;gt;&amp;gt; babarot.me +nostats +nocomments +nocmd ;; global options: +cmd ;babarot.me. IN A babarot.me. 3185 IN A 185.199.110.153 babarot.me. 3185 IN A 185.199.108.153 babarot.me. 3185 IN A 185.199.111.153 babarot.me. 3185 IN A 185.199.109.153 2.</description>
    </item>
    
    <item>
      <title>2019年振り返り</title>
      <link>https://tellme.tokyo/post/2019/12/31/2019-review/</link>
      <pubDate>Tue, 31 Dec 2019 23:59:04 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/12/31/2019-review/</guid>
      <description>仕事  1月からはメルペイの仕事に積極的に関わる機会があり、そのときに HashiCorp Vault を深ぼることから始まった。 Vault のドキュメントを漁って Vault on GKE のデザインからやることができた。しかしまだまだVaultビギナーなのでもっと追えるようにしようと思っている。
それからのちの GoCon Fukuoka で発表することにもなるが、Cloud Functions をもちいた Microservices の成果の観測を始める Project を作った。 Cloud Functions を大量に作ったのだけど、これを効率的に扱ういい方法がまだ見つかっていない。Serverless framework はあるのだけど、Lambda でさえそこまでアクティブにメンテナンスされていないようで、ここらへんはコントリビューションのしがいがあるかなーと睨んでいる。
そのあとは、Platform (主に Terraform 管理レポジトリ) の US 対応をしたりした。 Platform のグローバル化は Platform チームの目指すべきところでもあり、メルカリチームの悲願でもあるのでそこに貢献できたのはグッド。
10月からはバタバタしているうちに12月になってた。
コントリビューション  Software Design 2019年9月号 12 OSS projects (incl. private repos)  b4b4r07/stein https://github.com/b4b4r07/stein/    海外カンファレンス  HashiCorp &amp;lsquo;19 re:Invent &amp;lsquo;19  登壇  (mercari.go#6) Testing with YAML - Speaker Deck (GoConference &amp;lsquo;19 Summer in Fukuoka) Cloud Functions in Go at Mercari - Speaker Deck (Kubernetes Meetup Tokyo #18) Kubernetes manifests management and operation in Mercari - Speaker Deck (未来大×企業エンジニア 春のLT大会) Insert an Example of Software Engineer Here - Speaker Deck  プライベート  越して2年を迎えた。そろそろ引っ越したいなぁ</description>
    </item>
    
    <item>
      <title>2019年に読んだ本、観た映画</title>
      <link>https://tellme.tokyo/post/2019/12/28/2019-books-movies/</link>
      <pubDate>Sat, 28 Dec 2019 19:01:59 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/12/28/2019-books-movies/</guid>
      <description>本に関しては記録がないので直近で記憶に残ってるやつ。映画は Filmarks ベース。
本 韓国 行き過ぎた資本主義 ちょうど映画で観た「パラサイト 半地下の家族」で描かれている貧困問題などがどのようにして形成されたのか、を経済的な観点からレビューしているので面白い。97年に韓国を襲ったIMF危機についても解説しておりこれも映画「国家が破産する日」に連動するので面白い。
いわゆるA級戦犯 今の政治経済を勉強しようと思ったときに、今の体制の根本は戦後の憲政から学ぶとキャッチアップがしやすいなと思ったので、戦後GHQが採った占領政策から学ぼうと思って読み始めた。これを読んで自分もそうだけど多くの人が「A級戦犯」や戦後の自虐史観や占領政策のことを何も知らないなと思った。
奇跡の経済教室 現代貨幣理論（MMT）を勉強していく中でそのベースとなる部分を勉強しようと思って読んだ。インフレとデフレ、高校の政治経済の授業で習ったようなことがなぜどの政権でも実施できないのかと思った。いわゆる「失われた30年」は自ら捨てているようなものじゃねえか。返せワイの平成
実践Terraform 話題になってたやつ。Kindleで出てたので読んでみた。AWSがメインの題材、GCPだったらより楽しかったかな。
苦しかったときの話をしようか 筆者の娘さんが就職をしようとなったときに、何をしたらいいのかと迷いあぐねていたのをみて「なぜ今の若者は夢を持てないのか」と感じたらしい。それは自分自身をよく知らないからだという1つの仮説から、どのようにして自分の軸を見つけて、やりたいことを探すか、ということを筆者の経験や体験ベースで書いた本。内容自体はまあそうだよねーって感じだったけど、改めて文字に起こされて脳内に入れられるとフムフムってなった。
映画 1. パラサイト 半地下の家族 これは間違いない。今年ダントツ1番かも
どんよりダークな感じ。これぞTHE・韓国映画っていうラスト！韓国の行き過ぎた経済格差の風刺も効いてる。マストウォッチ
2. エルカミーノ ブレイキング・バッドの公式な続編。Afterホワイト先生の世界をジェシー目線でいい感じに描いていて最高にグッド
3. ホテル・ムンバイ 2008年にインドの五つ星ホテルで実際に起きたテロに立ち向かったホテルマンと宿泊客の話。何が印象に残ったかってテロリストが100%の悪だと言えない形で描いていたこと。テロリストもまた被害者で彼らなりの正義に突き動かされてるんだなーと
4. アルキメデスの大戦 巨大戦艦（後の戦艦大和）を建造したい大艦巨砲主義に突き動かされる平山陣営と、これからは航空機の時代だと空母を作りたい山本五十六陣営。提出された大和建造の見積もりが明らかに疑わしくその不正を暴くために五十六陣営に雇われた数学科の学生カイタダシのお話。
この映画の何が良かったって大迫力のVFXで描く大和がカッコいいってのはあるんだけど、1番は平山忠道造船中将（造船エンジニア、設計技師）が言ったカイタダシに向けて言った言葉。
（平山案の大和建造費の不正を暴くために再度大和を白紙から設計する過程を踏んだ彼に対して）
 君はこの艦を君自身で1度作り出した事があるはずだ
 そうなんだよ。しかも相手が寄越してきた見積もり案から大和の全貌を紐解いて、相手が作ろうとしているであろう戦艦の設計図を描いちゃった。しかもその中で相手が犯した設計上の欠陥まで修正を考慮して描いちゃった。これはSaaSをちょっと触ってそのアーキテクチャを想像してフロントエンドとバックエンドを実装しちゃった感じだな、ソフトウェアエンジニア的にいうと。こんなことしちゃったらダメもとでもリリース（建造）したくなるよね。実際にプロダクションで動いてリクエストを受ける様を見たくなる。クローズされるとわかっていても。その設計技師・技術者の性をくすぐりつつも、それとは別の理由で（政治的な意味合いで）なぜ沈むとわかっている大和を建造しないといけないのか、説明されたときに項垂れる他なかった&amp;hellip;
 それでも日本人はまた戦艦「大和」をつくるだろう〜この国が抱える根本的な宿痾（三田紀房,戸高一成） | 現代ビジネス | 講談社（1/6） エンターテインメントで〝反戦〟打ち出す　「アルキメデスの大戦」の山崎貴監督：時事ドットコム 【ネタバレあり】『アルキメデスの大戦』感想・解説：大和に新解釈を提示する王道歴史ミステリ | ナガの映画の果てまで 山崎貴監督が語る｢アルキメデスの大戦｣とVFX | 映画界のキーパーソンに直撃 | 東洋経済オンライン | 経済ニュースの新基準  5. 牝猫たち (2017) （映画の説明省略）
池袋感（外面・内面）がすごい。3人の視点でのアングラ世界の描き方は良かったんだけど、最終的に3人とも客に求めてるものが同じに収束していくのは客側（もしくは第三者視点で）の理想論すぎるかなと。実世界では結末がないからかもしれんけど現実ではああいう収束の仕方はないだろうなと
振り返り もうちょっと読んだり観たりしたけど、文章にまで書き起こす気力をくれる奴ら..!って感じで厳選した。あともっとこまめに Filmarks でレビュー書こ。振り返るの大変。</description>
    </item>
    
    <item>
      <title>HashiConf &#39;19 に行ってきた</title>
      <link>https://tellme.tokyo/post/2019/10/03/hashiconf2019/</link>
      <pubDate>Thu, 03 Oct 2019 17:15:22 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/10/03/hashiconf2019/</guid>
      <description>HashConf &amp;lsquo;19 (9/9 - 9/11) に行ってきた。 HashiConf とは HashiCorp 製品自体の発表であったりそれと使って構築したアーキテクチャやノウハウについて共有するカンファレンスになっている。 今年はシアトルで開催された。
First time #HashiConf attendee from 🇯🇵 Excited for this conference! pic.twitter.com/ApdtsTenWu
&amp;mdash; @babarot ⚡️ (@b4b4r07) September 10, 2019  たくさん面白いキーノートがあったが中でも開発者の多くが歓声をあげていたのははやり初日の Armon (Co-Founder/CTO) の Terraform Cloud に関する発表だったと思う。ローンチ以降 Remote State しか扱えなかった Terraform Cloud が、このタイミングで大きく強化され Enterprise 版と遜色ないくらいにまで機能拡張されていた。今後、（個人ユースは Free ということもあり）サクッと Terraform 環境を構築したいときにマッチすると思う。
Announcing Terraform Cloud
さらに、Terraform Cloud / Enterprise に Cost Estimation の機能が追加された。これを有効にすると、「この apply によってクラウド使用量からこのくらいのコスト増減が見込める」といった見積もりがとれるようになる。たとえば、Policy を定義できる HashiCorp Sentinel と組み合わせて「このマイクロサービスは 1000USD まで」といったポリシーを書くことでコストの意図しない増加を防ぐといったことができるようになった。この機能はめっちゃ便利なので、これを使うためだけに Terraform Cloud を使う価値すらあると思う。</description>
    </item>
    
    <item>
      <title>Software Design 2019年9月号に寄稿しました</title>
      <link>https://tellme.tokyo/post/2019/08/27/sd1909/</link>
      <pubDate>Tue, 27 Aug 2019 22:14:34 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/08/27/sd1909/</guid>
      <description>およそ1週間ほど前に、Software Design 2019年9月号に寄稿しました。
Twitter では告知したのですが前に2017年7月号を書かせていただいたとき、ブログを更新していたことを思い出したのでこちらでも書いておきます。
担当させていただいた章は、
 作品で魅せるGoプログラミング 【8】Kubernetesなどの設定ファイルをテストするCLIツール
 になります（連載パート）。
前回に引き続き2回目です。 Goは好きな言語であり、なおかつ自作ツールの紹介だったのでとても嬉しいです。 ありがとうございました。
 関連  Software Design 2017年7月号に寄稿しました | tellme.tokyo  明日発売のSoftware Design 2019年9月号に寄稿しました。「作品で魅せるGoプログラミング」というテーマで、YAMLなどの設定ファイルに対してカスタムルールでlintできるsteinというツールについて紹介しました。ぜひご覧ください。
Software Design 2019年9月号｜技術評論社 https://t.co/kP4N2SdxEG
&amp;mdash; @babarot ⚡️ (@b4b4r07) August 16, 2019  </description>
    </item>
    
    <item>
      <title>メソッドを持った interface を要素に持つ struct への JSON Unmarshal</title>
      <link>https://tellme.tokyo/post/2019/04/10/json-unmarshal-with-interface-element/</link>
      <pubDate>Wed, 10 Apr 2019 23:42:51 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/04/10/json-unmarshal-with-interface-element/</guid>
      <description>interface要素を持つstructへのJSON Unmarshal - すぎゃーんメモ
これが参考になった。
ただ、このケースで上げているのは interface がどの struct で評価されればいいかわかっているケースだった。 例えば、これをキーに持つ JSON だった場合は struct A で、このキーがなかったら struct B で、みたいなケースは自分で JSON の中を読みにいって判別して Unmarshal する他ない。
具体例を示す。
type State struct { Modules []Module `json:&amp;#34;modules&amp;#34;` } type Module struct { Name string `json:&amp;#34;name&amp;#34;` Resources []Resource `json:&amp;#34;resources&amp;#34;` } // ちなみにメソッドを持っていない場合は // interface{} として Unmarshal されるのでエラーにならない type Resource interface { Get() // ... } type AWSModule struct { Name string `json:&amp;#34;name&amp;#34;` } func (m AWSModule) Get() {} type GCPModule struct { Name string `json:&amp;#34;name&amp;#34;` Project string `json:&amp;#34;project&amp;#34;` } func (m GCPModule) Get() {} こういう状況だと上のブログにもある通り、</description>
    </item>
    
    <item>
      <title>Kubernetes などの YAML を独自のルールをもとにテストする</title>
      <link>https://tellme.tokyo/post/2019/02/19/test-kubernetes-yaml/</link>
      <pubDate>Tue, 19 Feb 2019 21:40:24 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/02/19/test-kubernetes-yaml/</guid>
      <description>設定ファイルのメンテナンスの必要性 Infrastructure as Code の普及もありインフラの状態やその他多くの設定が、設定ファイル言語 (YAML や HCL など) で記述されることが多くなった。 Terraform HCL や Kubernetes YAML など、人が継続的にメンテナンスしなければならなく、その設定が直接プロダクションに影響を与える場合、そのレビューがとても重要になる。 具体的に例えば、「デプロイする Replica の数」や「Resource limit や PodDisruptionBudget が適切か」などレビューの中で注意深く見なけれなならない点などがあげられる。 加えて日々のレビューの中で、問題にはならないが「Kubernetes の metadata.namespace は省略できるけど事故防止の意味も込めて明示的に書きましょう」といった設定ファイルに対して強制させたいポリシーなどが生まれて、ひとつのレビュー観点になっていくことは自然である。
人がレビューの中で毎回見なければならないこと、毎回指摘すること、機械的にチェックできることはルールセットを定義して、それをもとに lint でチェックして CI で失敗させるのが効率的である。
YAML などのただの設定ファイル言語に対して「独自のルールを定義してそれをもとにテストする」ということは実は難しかったりする。
 garethr/kubeval: Validate your Kubernetes configuration files, supports multiple Kubernetes versions viglesiasce/kube-lint: A linter for Kubernetes resources with a customizable rule set  kubeval はマニフェストファイルの validator として機能する。例えば、integer として定義しなければいけないフィールドを string で定義していた場合に検知することができる。 kube-lint は決められた Kind (現在は Pod のみ) の決められたフィールドのチェックを決められたオペレータ (equal, not equal など) で違反していないかチェックすることができる。</description>
    </item>
    
    <item>
      <title>hashicorp/hcl2 を使って独自 DSL を定義する</title>
      <link>https://tellme.tokyo/post/2019/02/19/hashicorp-hcl2/</link>
      <pubDate>Tue, 19 Feb 2019 02:44:36 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/02/19/hashicorp-hcl2/</guid>
      <description>HCL2 とは HCL (HashiCorp Configuration Language) は HashiCorp によって作られた設定言語です。 HCL の目的はコマンドラインツールで使用するために、人間からも機械からも扱いやすく構成されていて、かつ特に DevOps ツールやサーバーなどを対象とした構造化構成言語であることです。
実装は hashicorp/hcl にあります。
実はこれの他に同時に Version 2 の実装も目下開発中のようです。
hashicorp/hcl2: Temporary home for experimental new version of HCL
このリポジトリでは HCL が元から持つ iteration と補間言語 HIL を組み合わせて、任意の式をサポートする単一の構成言語を目指しているようです。 要するに、設定ファイルでありながら、演算処理や式の評価といったプログラミング言語的な要素を持ち合わせます。
ちなみに、HCL は HCL2 との互換性は保証されていないため、application から使用する場合は latest ではなく vendoring したものを参照するのが好ましいです。 また、HCL から HCL2 への移行パスは想定されていないようです。 構文の見た目上は非常に似ておりベースデザインは元実装を引き継ぎつつも、拡張された部分については全く異なるアプローチで実装されているようです。 例えば HCL2 の実装の方はより堅牢なエラー処理を可能にする機能などが盛り込まれています。 HCL2 の開発が安定したらもとのリポジトリはアーカイブされ、こちらが HCL の本実装になるようです。
ちなみに、HCL2 を含んだ HCL 全体のデザインなどは次の PDF が参考になります。
HCL Documentation
HCL2 の機能 JSON や YAML のパーサでは、バイト列を Go の構造体に落とし込むことで各要素を Go プログラム内から扱えるようにしています。</description>
    </item>
    
    <item>
      <title>Go のコマンドラインツールを簡単にリリースする</title>
      <link>https://tellme.tokyo/post/2019/02/15/release-go/</link>
      <pubDate>Fri, 15 Feb 2019 01:09:19 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/02/15/release-go/</guid>
      <description>goreleaser のおかげで Go のバイナリをクロスプラットフォーム向けにビルドしてパッケージングして GitHub Releases にアップロードするステップがだいぶ簡単になった。
今までは、gox + ghr などを使ってそれらをスクリプト化したものを各リポジトリに用意する必要があったのが、今では goreleaser 用の設定ファイル (YAML) を置くだけでよくなった。
例: stein/.goreleaser.yml at master · b4b4r07/stein
しかしそれでもリリースするにあたっていくつかのプロセスが残っている。
 tag 打ち バージョン情報の更新 Changelog の更新  それらをスクリプト化して各リポジトリに置くと、スクリプトに改修や機能追加すると各リポジトリでアップデートしなきゃいけなかった。自分向けなので必ずやらなきゃいけないわけではないけど、毎回シェルスクリプトを書くのも億劫だし、git.io を使って共用できるようにした。
b4b4r07/release-go
使い方は簡単で raw のスクリプトを curl などで取ってきて bash にわたすようにする。
実際は Makefile なんかに書いておくとより便利になる。
.PHONY: release release: @bash &amp;lt;(wget -o /dev/null -qO - https://git.io/release-go) これを実行すると、
 gobump を使って semver 形式で bump up git-chglog を使っている場合は Changelog の更新 goreleaser の実行  を必要に合わせてプロンプト経由で対話的に実行することができる。</description>
    </item>
    
    <item>
      <title>GitHub のラベルを宣言的に管理する</title>
      <link>https://tellme.tokyo/post/2018/11/19/github-label-management/</link>
      <pubDate>Mon, 19 Nov 2018 20:08:07 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/11/19/github-label-management/</guid>
      <description>ソフトウェアの宣言的設定について &amp;ldquo;何かを管理する&amp;quot;となったときに、宣言的に設定できるようになっていると非常に便利である。 この宣言的設定 (Infrastructure as Code) とは、イミュータブルなインフラ (Immutable Infrastructure) を作るための基本的な考え方で、システムの状態を設定ファイルにて宣言するという考え方である。 具体的には Kubernetes のマニフェストファイル (YAML) だったり、Terraform のコード (HCL) が挙げられる。 この考え方は、インフラ領域に限らず、何らかの状態管理にはもってこいの手法である。
GitHub のラベルは Issues/P-Rs を管理するために便利な機能である。 しかし、リポジトリの規模やラベルの数が増えてくると、ラベル自体も管理する必要が出てくる。 実際に Kubernetes 規模のリポジトリになると、ラベル管理なしにはやっていられない。 ラベルを管理するための bot やツールすら動いている。 実際に Kubernetes のコミュニティでは現在 180 個近くのラベルが定義されており、同様のラベルが導入されているリポジトリが数十個ある。
 Labels - kubernetes/community  1つのリポジトリのラベルを管理するくらいならマニュアルでも可能だが、複数リポジトリとなるとリポジトリ間の同期が大変になってくる。 特に ZenHub などの GitHub Issues を使ったマネジメントをしている場合、ラベル名が一致されていることとその付随情報 (色や説明) の同期が必須になる。 人間が手で追加や変更をしていると、必ず差異が発生する。
ここで、冒頭に挙げた宣言的設定が有効な手段になる。
github-labeler の紹介 https://github.com/b4b4r07/github-labeler
宣言的設定の手法をラベル管理に持ち込むために、GitHub ラベルの定義とそれを作るリポジトリについて「YAML に書いたとおりになる」ツールを書いた。
例えば次のような YAML を書く。
labels:- name:area/securitydescription:Indicates an issue on security area.color:1d76db- name:kind/bugdescription:Categorizes issue or PR as related to a bug.</description>
    </item>
    
    <item>
      <title>『僕たちはファッションの力で世界を変える』を読んだ</title>
      <link>https://tellme.tokyo/post/2018/11/08/the-inoue-brothers/</link>
      <pubDate>Thu, 08 Nov 2018 22:37:54 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/11/08/the-inoue-brothers/</guid>
      <description> デンマークで生まれ育った日系二世兄弟、井上聡(1978年生まれ)と清史(1980年生まれ)によるファッションブランド。2004年のブランド設立以来、生産の過程で地球環境に大きな負荷をかけない、生産者に不当な労働を強いない&amp;quot;エシカル(倫理的な)ファッション&amp;quot;を信条とし、春夏は東日本大震災で被災した縫製工場で生産するTシャツ、秋冬は南米アンデス地方の貧しい先住民たちと一緒につくったニットウェアを中心に展開する。さまざまなプロジェクトを通して、世の中に責任ある生産方法に対する関心を生み出すことを目標にしている。聡はコペンハーゲンを拠点にグラフィックデザイナーとして、清史はロンドンでヘアデザイナーとしても活動。そこで得た収入のほとんどを「ザ・イノウエ・ブラザーズ」の運営に費やす。
 https://theinouebrothers.net/
とてもいい本だった。 井上兄弟は中央アンデス高地に暮らす人々とそこに生息するアルパカから採れる毛を利用した最高級ニットを手がけるブランドクリエイターである。 彼らの精神性とプロダクトに対する強い想いに感動したのでまとめておく。
ブランドが掲げるコンセプト「Style can&amp;rsquo;t be mass-produced」  “Style can&amp;rsquo;t be mass-produced&amp;hellip;（スタイルは大量生産できない）”
 5年前にファストファッションなどに代表される大量生産・大量消費社会のしわ寄せともいえる事件がバングラディシュで起きた 1。 欧米西洋日本をはじめとする先進国の人たちの、最新のファッションやトレンドの服を安くたくさん手に入れたいという気持ちに応えるために、1円でも安く受注できる工場を発展途上国に委託する。 そこでは若い女性が低賃金で過酷な労働を強いられている。 労働環境などは二の次で、生産数を増やすために違法な増築改造を続けたがゆえの事件だった。
もちろんこのビルのオーナーや現場監督が悪い、という話になるのだが、もとを辿ればその上流から来ている問題だった。 たとえハッタリだとしても「君のところより安く受注できるところがあるから切るよ」と言われてしまうと、現地の工場は大量の労働者を路頭に迷わせてしまう。 そうならないためにもとことんコストを切り詰めないといけない状況になっていた。 こういった潮流を作っているのはあくまでもファストファッションブランドであり、現地の労働者も、地球の裏にいる消費者もそのことに気づいていない。 知っているのはブランド側だけである。
イノウエブラザーズはこういった大量生産・大量消費にはやくから疑問をもち、エシカルを信条とし生産者から購入者（≠消費者) までのプロセスに関わるすべての人が幸せになれるような、ダイレクトトレードの先駆けとして活動をしているブランドだった。
最高のプロダクトを現地の人と一緒に作る  “チャリティではなくビジネス”とふたりがよく口にするのは、施しは一時的な助けになっても、自立を促すための手段にはならないと考えるからだ。
 印象に残った言葉に&amp;quot;チャリティではなくビジネス&amp;quot;というのがある。 彼らは何度もアンデスの地に足を運ぶ中で、社会的な不公平や貧困、高山地域での暮らしの厳しさなどを目の当たりにしていた。 そこで施しを与えることはできるけど、自分たちは一時的な助けではなく、あくまでは彼らはビジネスパートナーであり彼らと一緒になって最高のプロダクトを作り、値段は高くはなるかもしれないが、適切なものに適切な価格を添えて世界に発信することで、ひいては彼らの生活水準を上げることにつながると考えたいたからこその発言だった。
もともと中央アンデス高地に暮らす人々の暮らしにアルパカは馴染んでおり、人々はその毛を刈り売ることで生活していたが、刈るための道具が石器の類でうまく切れずに毛やアルパカを傷めてしまうだったり、アルパカの毛の細さで価値が変わることだったり、採れる部位で価値が変わることなどを知らないという現実があった。そこで彼らに毛刈りハサミや電動シェーバーだったりのことを伝えたり、毛の刈る部位によってパッキングして卸したりするように伝えたりなどのところから始めた。
フェアトレードによるアルパカ自体の保全や現地の人の暮らしをまもりたいという志しで、ペルーの高地にあるパコマルカアルパカ研究所とパートナーシップを築き、地元の放牧者が自らの生活様式から上手く利益を上げられるように援助している。現地の研究所と対話しながら、世界で一番高品質の「シュプリームロイヤルアルパカ」を開発するなど、現在ではアルパカ製品の世界的なエキスパートになっている。
感想として  「本当の価値を決めるのは、希少性でも価格でもない。そこにどれだけ、つくり手の熱い情熱と魂を込められるかなんだ」
 この言葉にある通り、ものづくりに対する熱すぎる情熱とアルパカ製品で世界一のプロダクトを作るということへの想いが込められていると思った。 井上兄弟は端々に&amp;quot;世界&amp;quot;だったり&amp;quot;正義&amp;quot;、&amp;ldquo;平和&amp;quot;だったりといった少しくさいような、独善的な表現を用いるがそれは軽々しく言っているわけではなく、本当にそうしたいと思って実行し、裏付けとなる行動とともに成果を出していて、生き様としてかっこいいと思った。そしてその生き様が作るプロダクトに反映されていて、そのストーリー性やバックグラウンドの惚れ込み、アイテムへの愛着が湧いた。
最近では、次の写真のように、長く愛用してほしいという想いから天然の防虫剤としても知られる楠にメッセージを刻印したものを付属してくれている。こういった自分たちのプロダクトへの愛情とそれを購入者へ伝えたいという気持ちを見ることができて、なんとも言えない嬉しいような感動のような気持ちが湧いた。
リファレンス  世界一のアルパカニットを作る兄弟「ザ・イノウエブラザーズ」とは？ 過酷な低賃金ビジネスはもうやめよう──『僕たちはファッションの力で世界を変える』 | BNL (Business Network Lab) | Eightが運営するメディア 最高のクオリティを求めて南米を旅する兄弟──ザ・イノウエ・ブラザーズ｜メンズファッションニュース｜GQ JAPAN    ファストファッションの裏側　ラナプラザの悲劇の意味 | エシカルファッションのセレクトショップ A Scenery Beyond&amp;hellip;のエシカルマガジン&amp;#160;&amp;#x21a9;&amp;#xfe0e;
   </description>
    </item>
    
    <item>
      <title>スムーズに Hugo でブログを書くツール</title>
      <link>https://tellme.tokyo/post/2018/10/16/write-blog-smoothly/</link>
      <pubDate>Tue, 16 Oct 2018 13:18:07 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/10/16/write-blog-smoothly/</guid>
      <description>このブログ (b4b4r07/tellme.tokyo) ではマークダウンで記事を書き、Hugo を使って静的ファイルを生成して GitHub Pages でホスティングしている。
とても便利なのだが、いくつか面倒な点がある。
 リアルタイムに記事のプレビューが見たいとなると、hugo server -D する必要があり、都度別コンソールで立ち上げるのが面倒 記事をあたらしく書き始めるとき hugo new post/&amp;lt;filename&amp;gt;.md を打つのが面倒 過去記事を編集するのが面倒 hugo を実行すると draft の記事も生成されてしまう (index には載らないが、生成されるので commit してしまう)  いろいろ面倒なので、Hugo でブログを書くだけのツール (hugo wrapper) を書いた。 hugo の上位互換というわけではなく、必要な機能の不便な部分だけを Override しているだけのツールなので合わせて使っていく。
tellme.tokyo/cmd/blog at master · b4b4r07/tellme.tokyo
Usage: blog [--version] [--help] &amp;lt;command&amp;gt; [&amp;lt;args&amp;gt;] Available commands are: edit Edit blog articles new Create new blog article 簡単な CLI ツールになっていて、ブログを編集するときに blog edit とすれば fzf が立ち上がって記事を選択できるようになっている。
$ blog edit &amp;gt; 39/39 &amp;gt; スムーズに Hugo ブログを書くツール Windows 時代の使用ソフト晒し Bind Address で少しハマった話 Hugo で PlantUML のようなシーケンス図を描画する Kubernetes 上で Credentials を扱う HashiCorp Vault の Unseal と Rekey 東京衣食住 Microservices Platform Meetupで話した 『ルポ川崎』を読んだ fzf との連携は b4b4r07/go-finder でやっている1。</description>
    </item>
    
    <item>
      <title>Windows 時代の使用ソフト晒し</title>
      <link>https://tellme.tokyo/post/2018/09/27/windows-era/</link>
      <pubDate>Thu, 27 Sep 2018 20:06:55 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/09/27/windows-era/</guid>
      <description>〜2013 年ごろまで Windows を使っていた (Windows 7 SP2 が最後)。 そのころはいろいろなフリーソフトにお世話になった。
画像はマイベストフリーソフト「あふｗ」。
一覧 ファイル管理  あふｗ 内骨格 Paper Plane xUI DF NexusFile X-Finder Easy File Locker  ファイル比較  df  ファイル名変更  練馬 Flexible Renamer ファイル名変更君 お～瑠璃ね～ま～  ファイル圧縮  Lhaplus Noah 7-Zip caldix  ファイル検索  Everything FileSeeker3 Locate32  ファイル暗号化  アタッシェケース ED TrueCrypt  ファイル移動  FireFikeCopy FastCopy  ブラウザ  Sleipnir kiki  アプリランチャ  CLaunch Fenrir CraftLauncher Clock Launcher cltc  IME  Google IME  テキストエディタ  Vim  オフィス  PDForcel pdfi pdft xdoc2txt SumatraPDF i2pdf LibreOffice  画像  ViX JTrim BatchGOO!</description>
    </item>
    
    <item>
      <title>Bind Address で少しハマった話</title>
      <link>https://tellme.tokyo/post/2018/08/16/bind-address/</link>
      <pubDate>Thu, 16 Aug 2018 00:55:17 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/16/bind-address/</guid>
      <description>以下の要件を満たして hugo server を立ち上げたいという要求がありテンポラリで対応することになった。
 hugo server はローカルではなく、ある GCE インスタンスで実行する ローカルから繋ぎたいが、ポートフォワードは使わない  この要件を満たすためには、
 GCE インスタンスに :1313 でつなぎに行けるようにポートを開ける (ファイアウォールの設定) ポートフォワードは使えないので、グローバル IP を取る (とりあえず Ephemeral)  以下を参考に Firewall rule を設定して、GCE インスタンスにアプライした。
How to open a specific port such as 9090 in Google Compute Engine - Stack Overflow
動作確認として適当に Serve するスクリプトで :1313 を LISTEN して nmap してみた。
package main import ( &amp;#34;net/http&amp;#34; &amp;#34;io&amp;#34; ) func helloHandler(w http.ResponseWriter, r *http.Request) { io.WriteString(w, &amp;#34;Hello world!</description>
    </item>
    
    <item>
      <title>Hugo で PlantUML のようなシーケンス図を描画する</title>
      <link>https://tellme.tokyo/post/2018/08/13/hugo-mermaid/</link>
      <pubDate>Mon, 13 Aug 2018 18:58:07 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/13/hugo-mermaid/</guid>
      <description>Hugo で PlantUML を描画して埋め込めないものかと調べていると、
 Add exec shortcode #796 - gohugoio/hugo・GitHub  Hugo の Shortcodes の機能を使って、HTML の生成をフックにしてレンダリングした後に埋め込む、みたいなことをできるようにする議論自体はあったものの進んでいないようで、他の案はないかと調べると PlantUML ではなく mermaid が良いとわかった。
vjeantet/hugo-theme-docdock にあったディレクトリ構成を真似て以下のようにした。
 b4b4r07/tellme.tokyo - f8fe64c・GitHub  Shortcodes を使って以下のようなシーケンス図を書くと、
{{\&amp;lt; mermaid align=&amp;quot;left&amp;quot; \&amp;gt;}} sequenceDiagram participant Alice participant Bob Alice-&amp;gt;&amp;gt;John: Hello John, how are you? loop Healthcheck John-&amp;gt;John: Fight against hypochondria end Note right of John: Rational thoughts &amp;lt;br/&amp;gt;prevail... John--&amp;gt;Alice: Great! John-&amp;gt;Bob: How about you? Bob--&amp;gt;John: Jolly good! {{\&amp;lt; /mermaid \&amp;gt;}} 次のようにレンダリングされる。</description>
    </item>
    
    <item>
      <title>Kubernetes 上で Credentials を扱う</title>
      <link>https://tellme.tokyo/post/2018/08/07/kubernetes-configmaps-secrets/</link>
      <pubDate>Tue, 07 Aug 2018 01:01:47 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/07/kubernetes-configmaps-secrets/</guid>
      <description>アプリケーションにロジックを外側から変更したい場合やソースコード外から設定されるべき情報 (API キーや何らかのトークン、その他の Credentials など) をアプリケーション側から読み取れるようにしたい場合がある。 よくある方法として、環境変数やフラグなどがある。
しかしこれらは往々にしてアプリケーションにハードコードされがちである (ロジックが書かれたファイル外に定義されたとしてもそれはハードコードに等しい)。 そうすると設定変更のたびにデプロイを必要とするし、言わずもがなセキュリティ的には厳しい。
またこの問題は、コンテナとマイクロサービスの領域において更に顕著になる。 同じデータを2つの異なるコンテナで参照する必要がある場合や、ホストマシンが使えないのでどうやってコンテナ内に渡すべきかを考える必要が出てくる。
実際にハードコードされたアプリケーションから環境変数に移し、それらをコンテナ化し Kubernetes に載せ替えてくステップを追う。
アプリ側にハードコードされた例 var http = require(&amp;#39;http&amp;#39;); var server = http.createServer(function (request, response) { const language = &amp;#39;English&amp;#39;; const API_KEY = &amp;#39;123-456-789&amp;#39;; response.write(`Language: ${language}\n`); response.write(`API Key: ${API_KEY}\n`); response.end(`\n`); }); server.listen(3000); language やAPI キーを変更する場合は、コードを編集する必要がある。 またバグやセキュリティリーク、ソースコードの履歴を汚すアプローチである。
これの代わりに環境変数を使う。
環境変数を使うパターン Step 1: 環境変数を読み込む var http = require(&amp;#39;http&amp;#39;); var server = http.createServer(function (request, response) { const language = process.env.LANGUAGE; const API_KEY = process.</description>
    </item>
    
    <item>
      <title>HashiCorp Vault の Unseal と Rekey</title>
      <link>https://tellme.tokyo/post/2018/08/02/vault-intro/</link>
      <pubDate>Thu, 02 Aug 2018 19:51:52 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/02/vault-intro/</guid>
      <description>環境 HashiCorp Vault 0.10.4
Seal/Unseal HashiCorp Vault (Vault) は起動しただけでは使えない。 Vault は Sealed / Unsealed という自身の状態を表すステータスの概念を持ち、これらを内部で保持する一部ステートフルなアプリケーションである。
Vault は起動時 (再起動、デプロイ後など) は Sealed 状態となっており、Secret の取得や保存など、あらゆるオペレーションができないようになっている。 これはセキュリティを高めるために Vault が用意したプロセスである。
Vault では暗号化したデータを外部ストレージに保存する (Secret Backend と呼ぶ) が、復号して取り出す際に暗号化に使用したキーを必要とする。 この暗号化キーも暗号化されたデータとともに Secret Backend に保存されるが、マスターキーという別のキーで暗号化キーを暗号化している (ちなみにこのマスターキーは Secret Backend には保存されない)。 そのため、何かデータを復号して取り出すには、暗号化キーを暗号化したマスターキーが必要になる。
 例
少しややこしいのでこれらを銀行に例えると、
 マスターキー: 銀行という建物に入るための鍵 暗号化キー: 銀行という建物の中にある保管庫の鍵 秘密: 銀行という建物の中にある保管庫の中にしまってある  (Vault では保管庫は銀行という建物の中にないので実際には少し違うが) 秘密を取り出すにはまず銀行の中に入るための鍵が必要で、その次に保管庫の鍵が必要になる。 また、保管庫の鍵は銀行内にあるが銀行に入るための鍵は銀行の外にいる (複数の) 行員が持っているため、この銀行の鍵を準備する (Unseal) 必要がある。
 上で説明したように、Vault でデータを取り出すためには、 Sealed 状態を解除する必要があり、そのためにはマスターキーが必要になる。 Vault サーバ (クラスタ) ははじめて起動するとき (Initialize) に、マスターキーを5つのシャードに分割して Vault クライアントに提示する (Unseal Keys)。 再度、マスターキーを構築するためには3つ以上のシャードを必要とする。 これにはシャミアの秘密分散法というアルゴリズムが用いられている。 ただし、Vault はこれらのシャードキーをどこにも保存しないので、Initialize をした者は別途保管する必要がある。</description>
    </item>
    
    <item>
      <title>東京衣食住</title>
      <link>https://tellme.tokyo/post/2018/08/01/tokyo-life/</link>
      <pubDate>Wed, 01 Aug 2018 03:48:04 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/01/tokyo-life/</guid>
      <description>五十音順。2018年版
衣  AURALEE DAIRIKU NEEDLES NEON SIGN UNUSED URU bukht crepuscule  食  BUZEN 山半 山長 (恵比寿) 源八 (北澤) 珈琲コーラル  (Swarm 保存済みから一部)
住  上野、稲荷町、入谷 下北沢 中目黒 代官山 広尾 新江古田 江ノ島 (神奈川県) 豊洲、東雲 鎌倉 (神奈川県) 高円寺 麻布十番  </description>
    </item>
    
    <item>
      <title>Microservices Platform Meetupで話した</title>
      <link>https://tellme.tokyo/post/2018/07/23/microservices-platform-meetup/</link>
      <pubDate>Mon, 23 Jul 2018 14:35:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/07/23/microservices-platform-meetup/</guid>
      <description>Microservices における Terraform の活用とユースケースについて話した。
Microservices とは UNIX の設計思想にもある Make each program do one thing well をもとに書き直し、1つのアプリケーションを複数のサービス (コンポーネント) に分割して、独立して稼働できるようにしたもの。
Monolithic architecture にも Pros/Cons があり、Microservices architecture にも Pros/Cons があるのだが、Monolith から Micrroservices へ移行する際の Cons の1つとしてインフラの Provisioning が挙げられる。 Monolith の場合だと、新機能の追加は同じコードベースをいじることで解決できることが多く、その場合既存のインフラを使いまわしてデプロイすることで実現できる。 しかし、Microservices の場合だと Isolation の観点からインフラを独立させる必要があり、新機能追加 (つまり、Microservices の新規作成) のたびにインフラを用意することがコストとなる。 また、アーキテクチャと同じようにチーム構成をサービス単位で自己組織化させる必要がある (Developer, QA, SRE, &amp;hellip;) のだが、各 Developer がインフラの準備をする必要がある。 インフラ構築・運用に不慣れな Developer をアシストしつつ、これらのブートストラップを自動化する Solution が必要になる。
こういった背景がありその問題点を解決するツールとして Terraform を導入し、Terraform Module を使って Automation / Infrastructure as Code しているという話をした。 この仕組みのおかげで今では Developer は One command で Microservices に必要なセットを構築することができるようになっている。</description>
    </item>
    
    <item>
      <title>『ルポ川崎』を読んだ</title>
      <link>https://tellme.tokyo/post/2018/05/29/repo_kawasaki/</link>
      <pubDate>Tue, 29 May 2018 12:18:56 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/05/29/repo_kawasaki/</guid>
      <description>本作は帯にある「ここは、地獄か？」という謳い文句のとおりに現代のディストピアと言われる神奈川県・川崎市 (とくに川崎区) を舞台に書かれたルポルタージュ (現地報告) である。
著者が川崎をテーマにルポルタージュを書くにいたったのは、2015年から立て続けに起こった川崎中一殺害事件や簡易宿泊所火災、ヘイトデモといった象徴的事件が背景にある。 こういった陰湿かつ世間を驚かせるような事件が相次いだ川崎区を、現代日本が抱える社会的問題を象徴する場所として捉えた上で、その事件のバックグラウンド (深層) に入り込むことで「今の川崎から見えてくるものは何か」という現地取材による連載から始まったものである。
川崎市 (川崎区を含む七区からなる) は長年、東京と横浜の間に位置する土地柄を生かしてベットタウンとして開発されてきた過去を持つが、市の最南であり東京湾に面する川崎区は今でこそ川崎駅周辺の観光地化などによりクリーンなイメージを持ちつつあるが、もともとはその臨海部・工業地帯という性格から、そこで働く労働者のための「飲む・打つ・買う」を中心に発展した区である。現在でも中心部から少し外れれば、ソープランドや競輪競馬といった合法的なものからや非合法な娯楽場なども数多く営業し、それらの資金が最終的に流れつく大きな事務所も門を構えているようだ。しかし、この区に住む労働者はその地理的・歴史的背景により多様化が進み、朝鮮や東南アジアや南米と言った多文化地域としての顔も持つ。そんなある種、日本の近未来を象徴とするような町に生きる人を本作では描いている。
 「川崎のこのひどい環境から抜け出す手段は、これまで、ヤクザになるか、職人になるか、捕まるかしかなかった。そこにもうひとつ、ラッパーになるっていう選択肢をつくれたかな」
 BAD HOP メンバーの T-pablow は言った。彼はテレビ番組の企画で十代のラッパーたちがフリースタイルで競い合う「高校生RAP選手権」で優勝したラッパーである。彼もまたラッパーとして若者の間で名を馳せる前、川崎にいる&amp;quot;捕まる系&amp;quot;の不良少年だった。本作で取材を受ける人たち、登場する人たちの多くは本当によく捕まる。そんな彼が取材で答えたセリフの中で印象に残ったものがあった。
 「オレらと同世代とか下の世代とかでやんちゃなヤツは、もともと、オレらの名前は知っていたと思うんですよ。そのへんはオレらが仕切ってたんで。逆に言うと、そいつらはオレらがどんな状況にいたのかも知ってる。だからこそ、ここまで来たっていうことが本当にすごいとわかるはずだし、それができるラップっていう表現が魅力的に見えたと思う」
 ちょっと前までは家にも帰らず夜な夜な悪さをしていたような少年が、家に帰らず他所で悪さをして歩くのではなく、夜な夜な公園にあつまり熱心にフリースタイルをやる、というほどにまで影響を与えていた。本作では、ラップという新しい風が川崎の少年少女の間を取り巻いて、少しでもディストピア・川崎サウスサイドに希望をもたらすものとして描かれている。
本作で大きく扱われているトピックとして、
 ラップ、ラッパー、ヒップホップがもたらした光 レイシズム系の問題、多文化地域が持つ闇 それに続くヘイトデモ 公営競技、風俗街、ドヤ街といった歓楽街に生きる人たち &amp;ldquo;川崎&amp;quot;の監獄に生きる少女  などが挙げられる。
もともと、連載による章立てでの取材ベースで話が進んでいる。しかし、出版にあたり大きく構成を見直した後にそれぞれのピースが他の章とリンクするような編纂が加えられており、ノンフィクションのルポルタージュでありながら、小説のように話のパズルがハマるような納得感があって読み応えがあった。 構成もさることながら、内容も上に述べたような話の比じゃないほどディープな取材、深層がブレイクダウンされていて、終始緊張感を持ちながら読み進められ一気読みしてしまった。今年読んだ本の中でもかなり面白く、&amp;ldquo;川崎&amp;quot;の今と過去、そしてそこにあった (そして一部は今もまだある) 事実をリアリティを持って知ることができるいい本だった。
とりあえず読んだほうが良い。</description>
    </item>
    
    <item>
      <title>Go から peco する</title>
      <link>https://tellme.tokyo/post/2018/04/25/go-finder/</link>
      <pubDate>Wed, 25 Apr 2018 02:11:37 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/25/go-finder/</guid>
      <description>peco とか fzf のようなフィルターコマンドが便利すぎて使わない日はないのですが、これらをどうしても Go プログラムに組み込んでしまいたいときが稀にあります。
どちらも Go で書かれているので、ライブラリとして使えるように提供されていれば import するだけなのですが、どちらも CLI (Command Line Interface) のみを提供しています。 CLI として作られている以上、シェルコマンドとして使うべきではあるのですが、そうすると何かと連携させたいとなった場合 (多くの場合はそうですが)、シェルスクリプトを書くことになります。 小さなものであればそれで構わないのですが大きめなツールになる場合、基本的にシェルスクリプトを書きたくないわけで、そうするとやはりどうしても Go から扱いたくなります。
シェルコマンドといっても CLI (Command Line Interface) なので、アプリケーションに精通したインターフェースである API (Application Programming Interface) と似たように考えることができて、CLI はコマンドラインに精通したインターフェースを持っているわけです。 そう考えるとコマンドのオプションはそのインターフェイスを通してコマンドに処理の変更を伝える起点と捉えることができます。
Go ではコマンドラインインターフェースとやりとりできる os/exec が標準パッケージとして使えるので、これをうまく使って CLI との通信部分を抽象化してラッパーライブラリとして実装できないか考えてみました。
https://github.com/b4b4r07/go-finder
go-finder というパッケージを作りました。
使い方は次のようになります。
finder - GoDoc
fzf, err := finder.New(&amp;#34;fzf&amp;#34;, &amp;#34;--reverse&amp;#34;, &amp;#34;--height&amp;#34;, &amp;#34;40&amp;#34;) if err != nil { panic(err) } fzf.Run() peco, err := finder.New(&amp;#34;peco&amp;#34;, &amp;#34;--layout=bottom-up&amp;#34;) if err !</description>
    </item>
    
    <item>
      <title>Go でシェルの Exit code を扱う</title>
      <link>https://tellme.tokyo/post/2018/04/02/golang-shell-exit-code/</link>
      <pubDate>Mon, 02 Apr 2018 23:42:39 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/02/golang-shell-exit-code/</guid>
      <description>CLI ツールはよく Go で書く。 (Go でなくとも) ちゃんとした CLI ツールを書こうとすると、Exit code とそのエラーの取り回しについて悩むことが多い。 今回は、何回か遭遇したこの悩みに対する現時点における自分的ベストプラクティスをまとめておく。
ToC
 Exit code とは Go における Exit code 高次での取り回し  CLI 側 処理側   まとめ  Exit code とは $ ./script/something.sh $ echo $? 0 $? で参照できる値で、0 は成功を表し、0 以外は失敗を含む別の意味を表す。取りうる範囲は 0 - 255 (シェルによって違うことがあるかも知れない)。
$ true $ echo $? 0 $ false $ echo $? 1 詳しくは、コマンドラインツールを書くなら知っておきたい Bash の 予約済み Exit Code - Qiita
CLI ツールとはいわゆる UNIX コマンドであることが多いので、その慣習にならって実装するのよい。 成功したら 0 を、失敗したらエラーメッセージとともに非 0 を返すといった感じ。</description>
    </item>
    
    <item>
      <title>煉瓦の家</title>
      <link>https://tellme.tokyo/post/2018/01/16/renga_no_ie/</link>
      <pubDate>Tue, 16 Jan 2018 00:45:23 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/16/renga_no_ie/</guid>
      <description>はじめに 『煉瓦の家』は中島卓偉による通算15作目のオリジナルフルアルバム。デビュー15周年を記念してリリースされた前作の『BEAT&amp;amp;LOOSE』とは Vol.1、Vol.2 の関係性があり、Beatles でいうところの『Rubber Soul』と『Revolver』にあたる。
彼いわく Vol.1 と Vol.2 のセパレーションも自然に決まり、『BEAT&amp;amp;LOOSE』が完成した時点で、すでに本アルバムに収録されている15曲も概ねできていたという。
前作はギターが中心のアルバムで今作はベースが中心のアルバムになっている。 卓偉の中で1〜8曲目までがいわゆるA面、9〜15曲目までがB面になるように意識して制作されている。 また、今まで作ったアルバムの中で一番ブリティッシュ色の強いアルバムになっているとも。 本作の楽曲については基本、ギター・ベース・キーボードは全部卓偉が演奏し、14曲目の『東京タワー』についてはドラムも初チャレンジで演奏されている。
01. 大器晩成  Angerme に提供した一曲 本作では卓偉バージョンで収録 マイナーコードの3つをメインに使用してリフで展開し、メロディだけ変わっていくスタイル 洋楽テイストなチューン 彼いわく20代のころに書いているともっと長いイントロがついたかもしれないが、30代になり引き算の編曲ができるようになったからこそこんなテイストに落ち着いたという  02. 続けろ  シングルナンバーの1つ 今回のアルバム収録に合わせて、ミックスのバランスが変わったりしている 彼のスタイルでは先にシングルを作ってアルバムに入れるスタイルではなく、アルバム曲をすべてつくってからシングルカットするスタイルでやっている  が、曲が完成した時点で2曲目にすることが決まっていた というのもドラムから走るロック定番なチューンのため   アップテンポなエイトビートで展開する デビューしてから15、6年やり続けたことへの思いなどを歌詞にし、ブリティッシュなテイストに仕上げている  03. おまえは持ってる  作中で一番短い曲 中学3年のころに書いたいた古い曲 曲調はストレートなパンクナンバーでシンプルなアレンジ 曲自体は古くからあるがアルバム作成時の37歳の卓偉によるアレンジなどを加えてようやく今回アルバムに追加 すごく昔に書いた曲などをアレンジし直して入れるなども結構好き  04. 一人になろうとしないで  ポップなチューン 歌詞のままだがリスナーや人々を励ますような曲 メッセージソングになっている  05. 御城寺梨紗 〜all good idols go to heaven?〜  BEAT&amp;amp;LOOSE を知っている人はニヤッとするかもしれない曲 ちなみにタイトルは架空の人物 BEAT&amp;amp;LOOSE に収録されている『サイトウダイスケ』という曲のアンサーソング  前作のニュースの続きを読むような意味でアンサーソングになっている   サイトウダイスケに引き続き芸人のタイムマシーン3号に解説、詞の中でニュースを読んでいる  彼らのラジオに参加した際にタイムマシーン3号山本のアイデアでこのような形になった   Vol.</description>
    </item>
    
    <item>
      <title>2017年振り返り</title>
      <link>https://tellme.tokyo/post/2018/01/05/looking-back-on-2017/</link>
      <pubDate>Fri, 05 Jan 2018 19:52:12 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/05/looking-back-on-2017/</guid>
      <description>もう年も変わってしまったけれど、去年どのような1年を過ごしたのかを振り返る。
1〜7月、SRE になったという記事でもある通り、環境や心境の変化もあってクォータの変わり目でもある7月のタイミングでチームを異動した。 それまでは JP チームでガイドだったり大型便向けの電話対応用の API を作ったり、配送周りで上がってくる問い合わせの技術対応をしていた。
少し戻って6月は、US アプリの刷新チームにてバックエンド API のサーバサイドエンジニアをやっていた。 入社からずっと JP のことをやっていたので、US に関わったのはとても新鮮だった。
7月、SRE になったのだけれど、まずなにをやるべきか、ということになった。 ちょうど全社的に Microservices 化に舵を切り出したころだったので、 「Microservices への技術転向を支える基盤づくりをする」SRE メンバーになることを当面の目標として、 そのために必要な技術の学習やキャッチアップを兼ねて、 社内ドキュメントツールとしてモノリシックに動いていた Crowi という Wiki サービスをコンテナ化して Kubernetes で構築してみることになった。
 メルカリ社内ドキュメントツールの Crowi を Kubernetes に載せ替えました - Mercari Engineering Blog  コンテナや Kubernetes、Spinnaker といった技術やツールを勉強しつつ、ミドルウェア自体のキャッチアップもこのときにやった。 仕事でありながら勉強できるという環境にあったので、とても貴重な体験だったかなと思う。 また、(今回は) Crowi という、
 Web アプリケーションを違うアーキテクチャに載せ替えるとしたときに考えるべきこと
 にフォーカスしながらミドルウェアの勉強ができたのもいい体験だった1。 各種ミドルウェア、ソフトウェアはそれぞれのマニュアルや技術書を読むことで得られるが、 システムに落とし込んで構成を組むときに思慮するというのは今までに経験がなかったのでよかった。
また、プライベートでははてなブログで書いていたブログをコンテナ化したり Kubernetes に載せたりして GKE の勉強をしていた (GCP のクーポンが切れたのでもう GKE には載っていない)。 ちなみにちょっとずつこっちにインポートしているが、以前のブログはまだ消してはいないので残っている。
 ブログをGKEで運用し、Spinnakerでデプロイする | tellme.</description>
    </item>
    
    <item>
      <title>2017年に購読したサービス</title>
      <link>https://tellme.tokyo/post/2018/01/04/subscribing-services-2017/</link>
      <pubDate>Thu, 04 Jan 2018 20:32:44 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/04/subscribing-services-2017/</guid>
      <description>これらに便乗して。
  とりあえず昨年通して購読していて思い出せるものだけ列挙した。
購読したもの Amazon Prime 3,900円/年
Amazon で買い物するから。
Netflix 950円/月
映画、頻繁にみるので。
とにかく Breaking Bad はおすすめ。4周した。
http://www.breakingbad.jp/
アルバカーキに行ってロスポジョスエルマノスのチキンを食べたい。
Dropbox 12,000円/年
学生のときにヘビーに使っていたんだけど、いまはもうほとんどアクセスしていない。 オンラインストレージ自体に依存する生活をしていないので切っても良いのだけれど、昔のファイルなどを整理して移すのが面倒でそのままになっている。
GitHub 7ドル/月
ソフトウェアエンジニアなので。
https://github.com/b4b4r07
Education Plan が切れてしまい、使っていた Private Repo が Disabled になったので支払いとしては去年から。
iCloud 130円/月
50GB のプラン。iPhone のバックアップとして。今はまだ半分くらい。
写真などなどいちいち Mac にバックアップ、とか考えなくて良くなったから便利。 iPhone を新調したら「iCloud から復元」するだけで、さっきまで触ってた端末と同じ状態になる。
minikura 250円x複数個/月
購読サービスかと言われると違う気もするけれど、月額課金している便利なサービス。
使わないのに捨てられないもの (手紙、思い出の品) とかを預けている。 あとはシーズンではない洋服とか。
Apple Music 980円/月
Google Play Music、LINE MUSIC、Spotify、AWA、色々試したけどこれになった。 所持している Apple 製品が多いことが決め手だと思う。
HomePod が来たらもっと便利になると思っている。
Dartslive 315円/月
最近出たベータ版の黒いほうのアプリが超絶便利。 そのうち Phoenix も課金するかも。</description>
    </item>
    
    <item>
      <title>決済をキャッシュレス化している</title>
      <link>https://tellme.tokyo/post/2017/12/05/cashless/</link>
      <pubDate>Tue, 05 Dec 2017 08:57:17 -0600</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/12/05/cashless/</guid>
      <description>現状 キャッシュレスに切り替えて1年以上になる。 上京とともに現金を使うスタイルをやめた。 地方だと完全キャッシュレス化は現実的ではないが、首都圏、少なくとも都内23区においては現金を使うことなく生活できている。
よく使う決済手段は3つ。
 LINE Pay (JCB) ANA VISA Suica (VISA) モバイル Suica  他にもいくつかカードを持っているが、常用しているのは LINE Pay と ANA VISA Suica の2つで、電子マネーは Suica に絞っている。 ANA VISA Suica カードはややこしい名前だが Suica 機能 (オートチャージ設定可能) が付いた View カードで、ブランドが VISA になっている。
決済手段 LINE Pay JCB で1枚選出するとなると LINE Pay 一択かなと思う。 最高クラスの還元率 (2%) にも関わらず年会費などは不要で、コンビニなどですぐに買うことができる。 ほぼクレジットカードのように使うことができる1が、実態としてはプリペイドカード。 口座を指定しておくことで、LINE のアプリから24/7で入出金することができる。 最近はセブン銀行にも対応した2ことで、万が一キャッシュが必要になった場合、口座から LINE Pay に移して現金化するといったことも可能になった。
後述するがモバイル Suica と組み合わせると、「JCB は使えないが Suica は使える」というケースにおいてもポイントを取得することができる。
ANA VISA Suica 国内では JCB は VISA/MasterCard に遜色なく使える3が、海外だとあまり使えるところがない。 分散させるために違うブランドで、なおかつ待遇・特典のいいものを選んだ。</description>
    </item>
    
    <item>
      <title>Kubernetes 開発環境構築のいろは</title>
      <link>https://tellme.tokyo/post/2017/12/01/kubeabc/</link>
      <pubDate>Fri, 01 Dec 2017 00:54:11 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/12/01/kubeabc/</guid>
      <description>はじめに Kubernetes2 Advent Calendar 2017 - Qiita 1 日目です。
Kubernetes 上で動かすアプリを作ることが多くなってきていると思いますが、従来のオペレーションとは違う方法で開発やデプロイなどを行う必要があります。 Kubernetes の実行環境として GKE を例に取ると、GCP プロジェクトやその中で作った GKE クラスタ、Kubernetes ネームスペースなど、見る必要のある領域が増えるとともに今までのやり方も変わるはずです。 本記事ではその際のユースケースと、それをいい感じにしてくれるツールを紹介します。
今いるクラスタは何か 本番環境と開発環境 (Prod / Dev) でクラスタを分けることは多いと思います。 その他にもクラスタを持っていることもあるでしょう。
Continuous Delivery のプラットフォームとして Spinnaker が注目されつつあるので、Kubernetes クラスタへのデプロイはこれに置き換わる可能性1はありますが、Spinnaker がサポートしていない Kubernetes リソース (例えば、PodDisruptionBudget など) については、まだ手動で kubectl apply せざるを得ません。 また、基本的なリソースに対する apply 相当のことが Spinnaker によってできるようになったとはいえ、まだまだ手動で apply を実行したい場面もあります。 そこで気をつけたいのは、今いるクラスタとネームスペースの確認です。
Spinnaker は「デプロイ先のクラスタ」と「どのイメージを撒くか (manifest file)」をセットにして内部に持っているので「意図しないクラスタに対して意図しない manifest file をデプロイしてしまう」といった誤操作は防げるのですが、これが kubectl apply による手動だと今いるクラスタと -f に渡すファイル次第で、互い違いにデプロイしてしまうなどの事故も起こしかねません2。 毎回指差し確認するのも面倒ですし、そもそも確認を徹底するというのは有効打ではないので、常に見えるところに表示しておくのがおすすめです。
 手前味噌ですが、現在の Kubernetes クラスタと GCP プロジェクトを表示できるコマンドを書きました。
$ .</description>
    </item>
    
    <item>
      <title>SREになった</title>
      <link>https://tellme.tokyo/post/2017/11/02/sre/</link>
      <pubDate>Thu, 02 Nov 2017 01:33:34 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/11/02/sre/</guid>
      <description>最近、といっても今年の7月からですが SRE チームにジョインしました。
そもそも SRE とは Site Reliability Enginnering の略です。 Google が提唱しました。 国内ではメルカリがいち早くに改名したことでも知られています。
インフラチーム改め Site Reliability Engineering (SRE) チームになりました - Mercari Engineering Blog
ところで、今からおよそ1年前に入社エントリを書きました。
新卒でメルカリに入社した話 | tellme.tokyo
この頃ちょうど SRE 研修という名目のもと1ヶ月半ほど SRE チームにて業務の一端を担当しました。 研修という名を冠していますが、最前線にいる SRE から普通にタスクをもらって仕事したりレビューしてもらえるという、とても貴重な経験でした。 このときにインフラレイヤでのアーキテクチャ/ネットワークの設計や、実際に SRE が担っている業務領域に興味を持ち、このキャリアパスで飯を食っていきたいと思ったわけです。 無事に研修も終わり元のチームに戻ったわけですが、それ以降以前にもまして、SRE チームの動向ややりとりを羨望してました。
メルカリではクォータの変わり目や定期的な面談などで他分野への興味など広く技術のことについて話す機会があります。 そういった機会を利用しつつたびたびそれとなく話をしていた程度で、メルカリ SRE は技術力の高いチームであることもあり恐れ多くあまり声を大にしていなかったのですが、そうするうちに年も変わりたまたまあるきっかけを得ました。 それは &amp;ldquo;deeeet さんという人&amp;quot;が入社するっぽいぞという情報でした。 以前から尊敬するエンジニアのひとりだったのでひどく興奮したのを覚えています。
ときどき社内で話したり Go のイベントの手伝いや打ち上げなどで話す機会も多くなり、そのたびに「いつ SRE 来るんだ？」をいうジョブをもらい嬉しくも再度自分の思いを正しく伝えようと考えるきっかけになりました。 それからは上長や先輩たちに 1on1 をお願いし、今後自分がどうしていきたいのかなどを相談し、異動へのバックアップをしていただきました1。
晴れて今年の7月から SRE チームにジョインしたわけですが、チーム異動こそがゴールではないので、引き続きやるべきことをやっていく次第です。 直近では以下のようなことに手を出しつつ、Kubernetes を最大限に活用した Microservices 領域での基盤づくりなどを担当しています。
 メルカリ社内ドキュメントツールの Crowi を Kubernetes に載せ替えました - Mercari Engineering Blog Cloud Identity-Aware Proxy を使って GCP backend を保護する | tellme.</description>
    </item>
    
    <item>
      <title>Cloud Identity-Aware Proxy を使って GCP backend を保護する</title>
      <link>https://tellme.tokyo/post/2017/10/30/cloud-iap/</link>
      <pubDate>Mon, 30 Oct 2017 15:02:23 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/10/30/cloud-iap/</guid>
      <description>Cloud IAP とは  Cloud ID-Aware Proxy（Cloud IAP）は、Google Cloud Platform で動作するクラウド アプリケーションへのアクセスを制御します。 Cloud IAP はユーザー ID を確認し、そのユーザーがアプリケーションへのアクセスを許可されるかどうかを判断します。 - https://cloud.google.com/iap/
 つまり Cloud Identity-Aware Proxy (Cloud IAP、または IAP) を使うことで、任意の GCP リソース 1 に存在するロードバランサに対して、許可された Google アカウントやサービスアカウントによるアクセスのみに絞ることができます。 また、このアクセスリスト (ACL) の追加や削除などは GCP のウェブコンソールから簡単に制御することができます。
設定方法 GLB を作成する IAP を使う場合、GCP 上にロードバランサ (LB) を用意する必要があります。 これは IAP が LB に対して設定されるからです。
本記事では GKE、GCE での設定方法について説明します。 現時点で GAE にも対応していますが今回は検証しません。
1. GKE GKE で外部に公開したサービス (の Ingress) に対して ACL を設定したい、などでしょうか。 Ingress リソースを作成すると、自動で GLBC (GCE Load-Balancer Controller) が割り当てられます。 これは、GCP のウェブコンソールからも確認できます (メニュータブから Network services &amp;gt; Load balancing)。</description>
    </item>
    
    <item>
      <title>Software Design 2017年7月号に寄稿しました</title>
      <link>https://tellme.tokyo/post/2017/08/05/sd1707/</link>
      <pubDate>Sat, 05 Aug 2017 19:03:28 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/08/05/sd1707/</guid>
      <description>およそ1ヶ月ほど前に、Software Design 2017年7月号に寄稿しました。
すっかり告知や宣伝を忘れていたのですが、バックナンバーとしてまだ購入できるようですので、気になった方はお手にとっていただけると幸いです。
担当させていただいた章は、
 第2章：理論編2 シェルスクリプト初心者から中級者への次の一歩
 になります。
学生時代はよくシェルスクリプトを書いており、そのアウトプットのほとんどを Qiita やブログに載せていたため、今回このような形1で紙本になるのはとても嬉しかったです。
また機会があれば書かせていただきたいなと思います2。
   その記事をきっかけにオファーをいただきました&amp;#160;&amp;#x21a9;&amp;#xfe0e;
 需要があるかはわかりませんが、けじめをつけるためにも zplug の解説はどこかでしたいな、とは思っています (しかし掲載先は 1 人アドベントカレンダーのほうがいいかも知れませんね)&amp;#160;&amp;#x21a9;&amp;#xfe0e;
   </description>
    </item>
    
    <item>
      <title>Crowi 用の API Client 書いて公式に取り込まれた</title>
      <link>https://tellme.tokyo/post/2017/04/04/023351/</link>
      <pubDate>Tue, 04 Apr 2017 02:33:51 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/04/04/023351/</guid>
      <description>Crowi というオープンソースソフトウェアの wiki があります。
 Markdown で書ける wiki で、
 Markdown をオートプレビュー URL (パス構造) でページを作成/表現できる リビジョンヒストリ (差分を管理してくれる) いいね、ブックマーク、ポータル機能、&amp;hellip;  などの特徴があって、とても便利なサービスです。
簡単に Heroku to deploy できるので気になる方は試してみてください。開発者向けにはオールインワンの Docker が有志によってメンテされているので、そちらを試してみても良いかもしれません。
go-crowi Crowi 用の API Client を Go で書きました。
 Go で API Client は初めて書いたのですが、@deeeet さんの記事が参考になりました。
https://deeeet.com/writing/2016/11/01/go-api-client/
もともと、Qiita:Team からの移行ツールを Go で書いていたのですが、Crowi API と通信する部分は外部パッケージとして切り出したほうが汎用的に良いなと、go-crowi を作りました。
https://github.com/b4b4r07/qiita2crowi
このツールは Qiita:Team からのエクスポート用の JSON を食わすと、指定した Crowi に記事を作成してくれるものです。Qiita から画像を取ってきてアッタチメントしたり、コメントなども移行してくれます。
Transfer to Crowi そして今日、Crowi のメインメンテナの @sotarok さんから公式においても良いかも、というお話をいただき transfer しました。
公式 SDK としたほうが多くの人に使ってもらえるし、ユーザに安心感も与えられるのでこの移譲には大賛成です。P-R も歓迎しています (おそらく自分がこのままメンテすることになると思います)。</description>
    </item>
    
    <item>
      <title>実用 Slack bot ヤマト編</title>
      <link>https://tellme.tokyo/post/2016/12/12/002116/</link>
      <pubDate>Mon, 12 Dec 2016 00:21:16 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/12/002116/</guid>
      <description>この記事は Slack Advent Calendar 2016 - Qiita の 12 日目です。
はじめに 最近のエンジニアは Slack に常駐していることが多くなってきたと思います。ゆえに bot が便利であることはご存知かと思います。受け取った文字列を echo する bot や、ランダムに画像を返す bot もその練習としてはいいですが、次のステップに bot を書くとしたら実用的なものを書きたいですよね ((記事の導入に関してはこの記事が LGTM なので併せて))。
配送状況を通知する そこで書いたのが、荷物 (ヤマト) の配送状況が変わったら通知してくれる bot です。
https://github.com/b4b4r07/yamato-bot
次のような機能を持ちます。
 bot yamato 追跡番号 とすると bot が追跡番号を監視するようになります 現在の配送ステータスを記憶するので変わったら通知してくれます  とりあえず、注文した荷物の追跡番号が発番されたら bot に向かって教えてやればよいです。すると bot は定期的に配送状況をチェックしてくれるようになります。
配送ステータスが変わると以下のように教えてくれるので、ユーザは荷物に対して受け身でいることができます。便利！
 まだ、積み残しも多いですがこれだけでも十分に便利でした。個人 Slack にでも通知してやりましょう。
謝辞 この bot では nanoblog さんによるヤマト運輸の配送状況を確認する API を使用しています。
 [WebAPI]ヤマト運輸の配送状況を確認するAPIを作ってみた [YamaTrack]ヤマト運輸の荷物問合せサイトを作成しました  終わりに この bot は Node.</description>
    </item>
    
    <item>
      <title>ログのタイムスタンプで UNIX 時間なのはツライって話</title>
      <link>https://tellme.tokyo/post/2016/12/06/211226/</link>
      <pubDate>Tue, 06 Dec 2016 21:12:26 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/06/211226/</guid>
      <description>tl;dr https://github.com/b4b4r07/epoch-cat
 UNIX 時間は読めないのでログファイル丸ごと食わせて、該当部分を変換するフィルタ作った  やり方は色々ある JSON とか LTSV とか combine とか、それらの複合で記録されてることの多いログファイルですが、たまにタイムスタンプが UNIX 時間になってることがあります。
これめっちゃつらくないですかね？&amp;hellip;とても普通の人間が読める形式じゃないです。素の JSON であれば、jq に食わせて Dates 系の関数 などで加工することは可能ですが、jq 1.5 以上((現在 2016/12/06 最新の安定版は v1.5))が必須で、かつ jq 構文を覚えたり都度調べる必要があります (jq は好きだけどあまり使わない構文を覚えるのは個人的に面倒)。
そもそもログファイルが JSON じゃない形式の場合は、以下のリンクにあるようなやり方を組み合わせて調べたり、もはや UNIX 時間になっている該当部分をコピペして date コマンドに投げたりして JST (や UTC) に変換することが多いです。
 $ date -d @1478745332.2113 +&amp;#34;%Y/%m/%d %T&amp;#34; # GNU date これ非常に面倒なんですよね。さらに言えば GNU date である必要があったり((GNU date コマンドで unix time 変換))して、ただログの時間を読みたいだけなのに無駄に考えることが多いです。
こまけぇこたぁいいから 時と場合であれこれ考えずに丸っとよしなにやってくれるフィルタあったら便利そう、ってことで書いてみました。
 https://github.com/b4b4r07/epoch-cat  別に難しいことはしてなく、cat コマンドの要領で UNIX 時間っぽい数字を RFC3339 形式に変換します。数値を何でもかんでも変換していたらとてもやってやれないので、誤爆を防ぐために 2000-01-01 00:00:00+00:00 以降の UNIX 時間 (946684800) にのみ反応します。ロケールは TZ 環境変数に従ってローカライズされます。</description>
    </item>
    
    <item>
      <title>最近の Vim のプラグイン管理について考える</title>
      <link>https://tellme.tokyo/post/2016/12/05/021806/</link>
      <pubDate>Mon, 05 Dec 2016 02:18:06 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/05/021806/</guid>
      <description>この記事は Vim Advent Calendar 2016 の 5 日目の記事です。
以前、neobundle.vim と vim-plug の比較記事を書きました((おい、NeoBundle もいいけど vim-plug 使えよ))。それから数ヶ月後、dein.vim が登場し、再び比較記事を書こうと思っていたのですが、気づけばあれから 1 年が経っていました((dein.vim リリース前に Shougo さんから記事を書いてほしいといった DM を受け取っていた))。この記事は半年前 (&amp;lsquo;16年8月頃) に大枠だけ書き Qiita の限定共有に投稿していたのものを Advent Calendar 向けに書き下ろしたものです((限定投稿していたのにも関わらず PV が多く、はてブが 12 付いていたので大部分を踏襲しつつ Shougo さんのインタビューを加えました))。
Vim プラグインの歴史 GitHub 以前 (〜2008年) 昔の話です。Vim script で拡張の機能を書いたらそのスクリプトを vim.org にアップして開発者同士で共有したり、ユーザがダウンロードして使っていたようです。おそらくコレが所謂「プラグイン管理」の始まりなのですが、このときはまだ手動で行われていたようです (残念ながら、このときはまだ Vim に出会っていなかったためその肌感は分かりません&amp;hellip;)。
例えば、こんな機能も Vim script で書いた拡張です (autogroup などは考慮してません)。
autocmd BufWritePre * %s/\s\+$//eVim 7 から Vimball という機能が Vim 本体に同梱されて、それからはこれを利用するユーザもいたようです。vim.org からアーカイブされたスクリプトを持ってきて、:so % したり、気に入ったら runtimepath 以下に置いて自動読み込みしたり。その頃の plugins ディレクトリは混沌としていたようです。ペライチのスクリプトが無造作に転がっており、同名ファイルに気をつけたりアップデートの情報は自分でキャッチしなければなりませんでした。</description>
    </item>
    
    <item>
      <title>builderscon tokyo 2016 に参加してきました</title>
      <link>https://tellme.tokyo/post/2016/12/04/154846/</link>
      <pubDate>Sun, 04 Dec 2016 15:48:46 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/04/154846/</guid>
      <description>引用
 buildersconは「知らなかった、を聞く」をテーマとした技術を愛する全てのギーク達のお祭りです
 tl;dr  builderscon tokyo 2016 に参加して、  裸で登壇された生 mattn さんを見て、 みんなを楽しませる技術力に凄いなぁと改めて思わされ、 自分も何か作りたい衝動に駆られた    Opening 牧さんによるオープニングでした。いきなり第2回開催予定の告知からスタートし会場が少しざわめきました。まだ、第1回の builderscon すら終わってないのに、このタイミングでの告知は、サプライズ感だけでなく絶対成功させるぞという気概を感じさせるとともに、コンセプトにもあるお祭りっぽさがあってとてもワクワクさせられました。
OSS は Windows で動いてこそ楽しい @mattn さんによる発表でした。僕ははじめてお目にかかりました。(見た目は) 普通以上に普通なのに、異常なエンジニアリング力です。改めて尊敬し直しました。Vimmer であり、時折 Go も書く自分としては一番楽しみにしていた発表でした。案の定、Go で Windows OSS 開発の未来が明るくなる話や、Vim の新作ネタプラグイン (畏敬の念を込めてネタプラグインと呼ぶ) などが発表されました。個人的に、Vim 界隈に長年貢献されてきた mattn さんと kaoriya さんのツーショットや、mattn さんの Vim 環境 (青っぽいリッチステータスラインに Solarized Dark なテーマ) を生で見られたことに感激しました。
php.ini について知る @uzulla さんによる発表でした。PHP を書くことが多くなった自分としては聞いときたいなと思い、聞いていたのですがやはり思った以上に知らないことが多く (PHP が ini を解釈するときは想像以上にゆるふわ) とても勉強になりました。&amp;quot;true&amp;quot; って true じゃないとか、ini ファイルのパス解決順序で最後に読まれた ini が適用されるので気づかないでハマってたり、なんかつらそうだという印象でした。良くも悪くもそこが PHP の特徴なところもあるようで、うまく折り合いながら向き合っていく気合が必要とのことでした。発表終了間際に発言されていた「php.</description>
    </item>
    
    <item>
      <title>運営として VimConf 2016 に参加してきた</title>
      <link>https://tellme.tokyo/post/2016/11/06/230902/</link>
      <pubDate>Sun, 06 Nov 2016 23:09:02 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/11/06/230902/</guid>
      <description>と、仰々しいタイトルにしましたが、株式会社ミクシィさんにて行われた VimConf 2016 の参加レポートです。自分は一般参加者としてではなく、一部運営に携わったのでその点について主に書ければなと思います。
tl;dr   VimConf 2016 のまとめ役として参加しました スライドの感想や資料については他の方のレポートを見てください 「ババロットさん、アイコン変えた方がいいよ」  まとめ役として参画した背景 ある日突然、社内 Slack の個人チャンネル (分報的なアレ) にてこんなポストが投げられました (リンクだけ)。
 [https://github.com/vim-jp/vimconf/issues/106:title]
二つ返事で参加レスをしたわけですが、これはノリで運営やってみました、とかでは全くないです。日々、Vim を使い vim-jp やその界隈の人たちのプラグインなどを使ったりし感謝していくうちに、いつかコミュニティに携わりたい・還元したいという気持ちが芽生えていたためです。たまたまこの煽りポストがいい後押しとなり、運営への参画を踏み出すきっかけになったのでした。
ひとり KPT まとめ役という肩書きで参加したわけですが、色々振り返ってみるとやり残したことや課題感、続けたいことなどが見えたのでまとめてみます。
 KEEP  VimConf 2017 への参画  せっかく自分の中に溜まったノウハウをここで途絶えさせるのは勿体無いので、次回も何らかの形で携わりたい。貢献し続けることも大切   参加率の良さ  9 割近くの参加率、総勢約 120 名での VimConf は初のこと。募集開始を遅らせたりなどの工夫があった。果たしてこれが功を奏したかは来年も試してテストしてみないとだけど   ケータリングの量  多すぎず少なすぎずで懇親会終わる頃にちょうど綺麗になくなった感。廃棄もほとんどなかったんじゃないかな。ここは自分ががっつり噛んでいたところなので見事な新卒力を発揮できた   交流が活発に見えた  誰とも話せない、という人はいなかった気がします。それとドリンク島がドリンクを求めた立ち寄った人との交流の場になっていたのは良かった     PROBLEM  コミットが足りなかった  TRY: 忙し月と準備が被った。次回も参加することで乗り越えていきたいところ   意外とバタバタ@懇親会準備1  TRY: 各種業者に当日リマインダを掛けられたのはよかった。ただ、一部到着連絡をもらえず開場まで運ばれたのには焦った (受付に人がいて気づいてくれた.</description>
    </item>
    
    <item>
      <title>新卒でメルカリに入社した話</title>
      <link>https://tellme.tokyo/post/2016/10/01/191546/</link>
      <pubDate>Sat, 01 Oct 2016 19:15:46 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/10/01/191546/</guid>
      <description>タイトルの通りです。16年卒の学部卒新卒として株式会社メルカリに入社しました。入社したのは今年の 4/1 なので半年前のことです。なぜ今頃になって入社エントリを書くのかというと、先日新しいメディア立ち上げにともなう記事一発目としてインタビューを受けたのですが、その記事が 10/3 に公開されるとのことで、他者に明らかにされるならばその前に自分から入社エントリを書こうと思ったことと、タイミング的にも今日という日はちょうどいいなと思ったからです。
tl;dr  新卒でメルカリに入社しました メルカリでは新卒採用もしているので興味があれば言ってください  メルカリという会社  メルカリが新卒採用を始めたのは今年からなので、僕は第一期新卒ということになります。最近ではとても有名なアプリ・会社になってきて、国内での勢いはもちろんのことアメリカでも急成長してきており、今後の動向にワクワクしつつ日々携わっております。
16 新卒は 6 人いて、今は 17/18 卒の新卒採用に向けて動いています。採用会食など、まずは話から聞いてみたいなという方がいましたら、僕経由で繋ぐことができるかもしれませんので興味があれば Twitter DM でもいいですし、コンタクトいただければなと思います。新卒・中途採用どちらでも OK ですし、時期に関しても関係ないと思います（次の新卒がこの時期に連絡しても問題ないのかという意味で）。
入社までの経緯 プログラミングといえるようなことは大学に入ってからはじめました。C 言語の開発環境 (bash on Linux) に慣れなかったことから、色々改善しようと .bashrc のカスタマイズにのめり込み、シェルスクリプトを覚えるようになりました。同時に Emacs に慣れずにエディタには Vim を使うようになり、同じく .vimrc のカスタマイズ (Vim script) にハマりました。夢中になって気づいたら朝ということも何度かあった気がします。
もともと、Windows を使っており、当時 AutoHotkey と超低機能 2 画面ファイラの「あふｗ」 (敬意を込めて) のカスタマイズにハマっていたことから、Linux でのカスタマイズについても夢中になることは明白でした。これを機にと macOS (当時の表記で言う Mac OS X。途中から OS X) に乗り換えたことで、更にそれは加速したような気がします。しかし、シェルスクリプト力とエディタ力は上がれど、なかなか他の言語を集中して覚えることがなく、しばしば悩んでおりました。
今も当時もインターンが流行っていて、「強い意志もなく流行りにのってインターンに行くくらいなら、家や大学に篭って自分の好きなツールを作ったり OSS 活動をしていたほうがマシだ」((今となってはインターンに行かなかったことを少し後悔しています))と思っていた僕の GitHub / Qiita は、このとき大変活発でした。
  そんな僕でも就職活動についてはせざるを得ないので、どうせなら自分のやり方でやろうと思い、大学で推奨されていた「マイナビ・リクナビ・研究室のコネ」は使わずに GitHub、Qiita を用いて行いました。自分の気になる・尊敬するエンジニアなどの Qiita 記事やブログ記事、GitHub の Bio からその会社を受けたり、Qiita Organization から興味を持った記事を書いているエンジニアのいる会社のウェブサイトを通して直接エントリしたりです。面接では必ず GitHub を見せ、「インターンは行ってないけどこれ作りましたよ」と言うことで、今まで作ってきたものベースで話を進めることができました。そのため就活は、自分の作ったものについてレビューをもらったり褒められたりして楽しかったな、という記憶しかないです。</description>
    </item>
    
    <item>
      <title>最近、httpstat なるものが流行っているらしい</title>
      <link>https://tellme.tokyo/post/2016/09/25/213810/</link>
      <pubDate>Sun, 25 Sep 2016 21:38:10 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/09/25/213810/</guid>
      <description>おそらく先行実装は python で書かれたこれです。
 curl にはウェブサイトの応答時間を計測する機能が搭載されており、このツールではそれを利用して出力結果をグラフィカルに表示させています。単なる curl のラッパーのようなツールなのですが、見た目がリッチになるのに加えて、単一ファイルで実行でき python のバージョンに影響されないような工夫がされているのが、受けているポイントのような気がします。
このツールを見たとき「Go で書いてみるの良さそう！（この手のツールで単一バイナリになるのは嬉しいですよね）」と思い、休憩時間やお昼休みなどにちまちま書いていたら、二日前に先を越されてしまいました（そりゃそうですよね。なんでもスピードが大事だと痛感）。
  また、ついこの間まで 800 Stars くらいだったのですが、ここ1週間で爆発的に伸びています（記事投稿時 1,100 Stars）。 これを機になのか、色々な実装を見るようになりました（Go 実装は Library として）。知らないだけで他にもあるかもしれません。
 [https://github.com/yosuke-furukawa/httpstat] (JavaScript) [https://github.com/tcnksm/go-httpstat] (Go) [https://github.com/talhasch/php-httpstat] (PHP)  Go で先を越され少し悔しい気もするので、curl のラッパーだしシェルスクリプトでも書いてみようと思い、書いてみました。なんのメリットがあるかは分かりませんが、bash オンリーで書いているので bash のある環境であれば動くはずです。
 次に時間があるときは Vim script で書こうかな。</description>
    </item>
    
    <item>
      <title>zplug では Collaborators を募集しています</title>
      <link>https://tellme.tokyo/post/2016/09/22/003448/</link>
      <pubDate>Thu, 22 Sep 2016 00:34:48 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/09/22/003448/</guid>
      <description>zplug は A next-generation plugin manager for zsh と謳い、絶賛開発中の zsh 向けのプラグインマネージャです。設計当初の目標通りフルスタックなツールになってきており、もはや zsh で書かれたというだけの、単なるパッケージマネージャとして使うことができるほどの機能を持ちはじめています。
どんな機能があるか、どんな使い方ができるかなどは公式の README をご覧ください。最近では、ドキュメントの多言語化にも取り組んでおり、日本語版の README も追加しました。お気に入りの機能として特筆すると、例えば C 言語で書かれたツールの管理もできます:
# インストール、アップデートに反応してビルドが走る zplug &amp;#34;jhawthorn/fzy&amp;#34;, \  as:command, \  rename-to:fzy, \  hook-build:&amp;#34; { make sudo make install }&amp;#34; 現在、zplug では @b4b4r07 と @NigoroJr さんの2人で開発・メンテナンスしております。@zplug-man は bot メンバーです。zplug ではコミュニケーション用に Slack を導入しており、Slack から zplug-man に作業させたりしています。
 Join us!  そんな zplug では Collaborators を募集しています。記述する言語は Shell Script (zsh) です。zsh では黒魔術みたいな記述がたくさん出てきます。例えば:
if (( $#unclassified_plugins == 0 )); then # If $tags[use] is a regular file, # expect to expand to $tags[dir]/*.</description>
    </item>
    
    <item>
      <title>Vim 8.0 がリリースされた</title>
      <link>https://tellme.tokyo/post/2016/09/12/232337/</link>
      <pubDate>Mon, 12 Sep 2016 23:23:37 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/09/12/232337/</guid>
      <description>本日 (2016-09-12 21:24:19 +09:00)、Vim 8.0 がリリースされました。
メジャーアップデートは 2006 年 5 月の Vim 7.0 以来なのでおよそ 10 年ぶりです。おめでとうございます！
 [https://github.com/vim/vim/commit/bb76f24af2010943387ce696a7092175b4ecccf2:embed:cite]
Vim は GitHub に移行したので最新の Vim 8.0 をインストールするには、
$ git clone https://github.com/vim/vim $ cd vim $ ./configure #好きな引数 $ make &amp;amp;&amp;amp; sudo make install でよいです。めっちゃ簡単
変更点はリリースノートを見ましょう。私は絶賛試している最中です。
 Happy Vimming!
[https://github.com/vim/vim:embed:cite]</description>
    </item>
    
    <item>
      <title>最近の zplug の変更について</title>
      <link>https://tellme.tokyo/post/2015/12/21/122701/</link>
      <pubDate>Mon, 21 Dec 2015 12:27:01 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/12/21/122701/</guid>
      <description>zplug 公開から今日で1ヶ月。いくつかの機能を追加した
1. ローカルプラグインを管理できるようになった 先日の issue（#54）によってローカルリポジトリをロード対象とすることが可能になった。neobundle.vim や vim-plug にもあるお馴染みの機能だ。
zplug &amp;#34;~/.zsh&amp;#34;, from:local from タグを使って指定する。自分の場合、~/.zsh 以下で zsh の設定ファイルを次のように分割しているため、この機能はとても便利に働く。デフォルトでは &amp;quot;*.zsh&amp;quot; が読み込み対象になっているので ~/.zsh 以下の zsh ファイルを簡単に zplug で管理できる
$ tree ~/.zsh /Users/b4b4r07/.zsh ├── 10_utils.zsh ├── 20_keybinds.zsh ├── 30_aliases.zsh ├── 40_prompt.zsh ├── 50_setopt.zsh ├── 60_export.zsh ├── Completion │ ├── _ack │ ├── _add-sshkey-remote │ ├── _ag ... │ └── _path ├── Makefile └── README.md フルパスでない場合は $ZPLUG_HOME を基準にパス解決される。
zplug &amp;#34;repos/user/repo&amp;#34;, from:local 2. 読み込むファイルを一部無視できるようになった これもまた issue（#56）によって導入された機能で、of タグと逆の指定をするためのタグ ignore が使用できるようになった。</description>
    </item>
    
    <item>
      <title>zplug を使った zsh プラグイン管理術</title>
      <link>https://tellme.tokyo/post/2015/12/13/174209/</link>
      <pubDate>Sun, 13 Dec 2015 17:42:09 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/12/13/174209/</guid>
      <description>zplug とは zsh のプラグインマネージャ。
https://github.com/b4b4r07/zplug
 何でも管理できる（コマンド、Gist、oh-my-zsh のプラグイン、GitHub Releases のバイナリ） 非同期インストール/アップデート ブランチロック・リビジョンロック インストール後の コマンド実行 hook あり oh-my-zsh などの外部プラグインをサポート バイナリを管理できる（GitHub Releases） shallow clone できる（オン・オフ） 依存関係の記述ができる ユーザはプラグインマネージャのことを考えなくていい（*.plugin.zsh 不必要） 選択的インターフェイスとの連携（fzf, peco, percol, zaw）  書き方 zplug はタグという概念を持っている。タグとはプラグインの属性情報を表したもので、タグ:値 のセットで記述していく。
zplug &amp;#34;foo/bar&amp;#34;, as:command, of:&amp;#34;*.sh&amp;#34; こんな具合である。各タグ間はカンマと一つ以上のスペース（,　）で区切る必要がある。タグの値は必ずしもクォートで括る必要はないが、ワイルドカードなどファイルグロブを値と指定する場合、シェルに展開されないようにクォーティングする。
タグ一覧 現在利用できるタグは以下のとおり。
   タグ 説明 値 (デフォルト値) 例     as コマンドかプラグインかを指定する plugin,command (plugin) as:command   of source するファイルへの相対パスかパスを通すコマンドへの相対パスを指定する（glob パターンでも可） - (&amp;quot;*.zsh&amp;quot;) of:bin,of:&amp;quot;*.sh&amp;quot;   from 外部からの取得を行う gh-r,gist,oh-my-zsh,github,bitbucket (github) from:gh-r   at ブランチ/タグを指定したインストールをサポートする ブランチかタグの名前 (master) at:v1.</description>
    </item>
    
    <item>
      <title>zsh のプラグインマネージャ</title>
      <link>https://tellme.tokyo/post/2015/11/24/142143/</link>
      <pubDate>Tue, 24 Nov 2015 14:21:43 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/11/24/142143/</guid>
      <description>antigen ですよね、やっぱり。最近は antigen の軽量バージョンである zgen もアツいようです。
僕も同様に、最初は antigen 使っていたんですが、まずプラグインの読み込みが遅い（tmux でペインを頻繁に開いたりする身からするとローディングが遅いのはツライ）のと、antigen 自体の機能が貧弱で困ってました。例えば、antigen はプラグインしか管理してくれませんよね。コマンドも管理しようとすると一工夫するしかありません（例: b4b4r07/http_code）。それに、fzf や jq など CLI ツールとしては有用でもコンパイルする必要があるものの管理は不可能でした。
zplug すべての要望に応えるプラグインマネージャをスクラッチから作っています。
  b4b4r07/zplug

 並列インストール（擬似マルチスレッド） ブランチ/タグ指定 コマンド管理（言語は問わない） バイナリ管理（GitHub Releases 限定） ビルド機能（インストール時に任意のコマンドを実行） 限定インストール（条件が真のときのみインストール） 依存関係の管理    まだまだアルファ版でトータルの完成度でいうと antigen には及ばないのでこれからです。 年内のリリース（あわよくば Advent Calender でリリースしたい）を目指して開発中です。
設定は以下のような感じで書けるようにしています。
source ~/.zplug/zplug # Make sure you use double quotes zplug &amp;#34;zsh-users/zsh-syntax-highlighting&amp;#34; zplug &amp;#34;zsh-users/zsh-substring-search&amp;#34; # shell commands zplug &amp;#34;holman/spark&amp;#34;, as:cmd # shell commands (specify export directory path using `of` specifier) zplug &amp;#34;b4b4r07/http_code&amp;#34;, as:cmd, of:bin # shell commands (whatever language is OK; e.</description>
    </item>
    
    <item>
      <title>HTTP のステータスコードを簡単に調べる</title>
      <link>https://tellme.tokyo/post/2015/11/07/165928/</link>
      <pubDate>Sat, 07 Nov 2015 16:59:28 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/11/07/165928/</guid>
      <description>HTTPステータスコードは、HTTPにおいてWebサーバからのレスポンスの意味を表現する3桁の数字からなるコードで、RFC 2616、RFC 7231等によって定められている。via HTTPステータスコード - Wikipedia
 403とか404はよく目にもするので覚えていますが、300番台は？500番台は？とかとなると思い出せないことが多いです。いちいちググり直すのも手間。そんなときに、bash なりのシェルにてエイリアスとして登録しているハックを目にしました。
 Jxck/dotfiles - GitHub  このまま参考にさせてもらおう、と思ったのですがすべて登録するのもな、と思いコマンドで用意しました（番号が変わるものでもないので一度登録して変更することになる心配がないためエイリアスもいいと思います）。

 b4b4r07/http_code - GitHub  antigen で簡単にインストールできます。
$ antigen bundle b4b4r07/http_code antigen でない場合は、
sudo sh -c &amp;#34;curl https://raw.githubusercontent.com/b4b4r07/http_code/master/bin/http_code -o /usr/local/bin/http_code &amp;amp;&amp;amp; chmod +x /usr/local/bin/http_code&amp;#34; しかし、antigen でインストールしたほうが、補完ファイルなども使用できるようになります。
使い方は gif アニメにもある通り、-a/--all オプションをつけると一覧表示、引数に数字を渡すとそれに対する説明を返します。</description>
    </item>
    
    <item>
      <title>MacBook 12 inch を買った</title>
      <link>https://tellme.tokyo/post/2015/08/14/120049/</link>
      <pubDate>Fri, 14 Aug 2015 12:00:49 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/08/14/120049/</guid>
      <description>MacBook 12 inch を買った  5/20 に「新しい MacBook」が届いた．Apple のオンラインの Store で，実際にポチったのは4/12なので届くのには1ヶ月以上かかったことになる．
スペックはこの通りだ．
 CPU を最大の 1.3GHz に引き上げた．処理スピードは速いに越したことはない．それと，ここに載っていない変更点として，キーボードを US 配列にした．これはデザイン的な動機もあるが，主として私の用途がプログラミング関連だからだ．デスクトップ PC にも US 配列のキーボードを使用している．
 Why なぜ，この賛否両輪ある新しい無印の MacBook を買ったかというと，それまで使っていた MacBook Air (13 inch, Mid 2012) に不満が溜まってきていたからだ．
 13インチはモバイル機としては大きすぎる メモリが 4GB（初のモバイル Mac だったため勝手がわからなかった） キーボード（特にスペースキー）の反応が悪くなり始めた MacBook がかっこ良すぎた  上2つが特に大きな動機だった．MacBook が発表される前，一度 MacBook Air 11 inch を検討していたくらいに軽さ・小ささを求めていた．
以前，iPad（Airの前）を所有していた．買った当初は頻繁に持ち歩いていたもの，その重さや大きさからか徐々に持ち運ばなくなっていた．そこで，それを売っぱらって iPad mini を買うことにした．iPad mini にしてからは持ち歩くことが増え，また片手でひょいと持ちやすかったため，トイレやらキッチンやら隙間時間を生み出しそうなところには常に連れ歩いた．この携帯性がノート PC にも欲しかった．出かけるとき，ひょいと「PC 使うかわかんないけど持っていくか」となりたかったのだ．
いざ買ってみて 満足か，後悔か．もちろん大満足である．とにかく軽くて小さい Mac PC（UNIX 端末）が欲しい人にはピッタリなノート PC だと思う．賛否両論あるポイントを中心にレビューしてみる．
 USB-C USB-C はまったく新しい規格だ．USB 系の正統進化で，リバーシブルに着脱でき，また給電からデータ転送までマルチな役割を一手に担う．MacBook では，その新しい規格のポートをたったひとつしか採用しなかったことで大きな論争をよんだ．</description>
    </item>
    
    <item>
      <title>Go でコマンドラインにゴミ箱を実装した話</title>
      <link>https://tellme.tokyo/post/2015/05/22/103912/</link>
      <pubDate>Fri, 22 May 2015 10:39:12 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/05/22/103912/</guid>
      <description>Go でコマンドラインにゴミ箱を実装した話 - TELLME.TOKYO
移設しました。</description>
    </item>
    
    <item>
      <title>enhancd という autojump/z ライクな bash/zsh プラグインを書いた</title>
      <link>https://tellme.tokyo/post/2014/11/20/134901/</link>
      <pubDate>Thu, 20 Nov 2014 13:49:01 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2014/11/20/134901/</guid>
      <description>【追記 2015-07-21】
拡張版 cd コマンドの enhancd が生まれ変わった - tellme.tokyo
enhancd v2.0 として生まれ変わりました。 enhancd [ɛnhǽn-síːdí] b4b4r07/enhancd.sh - GitHub  enhancd.sh とは autojump や z.sh などにインスパイアされて、後述する cdhist.sh をベースに作成されたディレクトリ移動をサポートするツールのことで、今回はそれらにも勝るとも劣らない機能を追加・拡張したので公開することにした。
作った経緯 Bashの小枝集にて紹介されている cdhist.sh というものがある。これは説明にもある通り
 ブラウザの「戻る」や「進む」のようにカレントディレクトリを行ったりきたりできるコマンド。これはリング状のディレクトリバッファを持っており以下の様な使われ方をする&amp;hellip;（※都合により引用を解釈の変わらない程度に変更）
 yusuke ~[1]$ . cdhist.sh # (cdhist を起動) yusuke ~[2]$ cd /tmp # (カレントディレクトリが /tmp に移る) yusuke /tmp[3]$ cd /usr/bin # (カレントディレクトリが /usr/bin に移る) yusuke /usr/bin[4]$ - # (ひとつ前に戻る) yusuke /tmp[5]$ cd /etc # (カレントディレクトリが /etc に移る) yusuke /etc[6]$ - # (ひとつ前に戻る) yusuke /tmp[7]$ + # (ひとつ後に進む) yusuke /etc[8]$ = # (ディレクトリの履歴一覧表示) 3 /usr/bin 2 ~ 1 /tmp 0 /etc yusuke /etc[9]$ = 2 # (リスト上のディレクトリを直接指定) yusuke ~[10]$ というスクリプトである。しばらくこれを満足して使っていたのだが、いくつかの不満点を抱くようになった。</description>
    </item>
    
  </channel>
</rss>
